{
  "paragraphs": [
    {
      "text": "%md\n# Example K-Means",
      "dateUpdated": "Mar 22, 2016 8:27:48 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458674842743_53392556",
      "id": "20160322-202722_1742025012",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch1\u003eExample K-Means\u003c/h1\u003e\n"
      },
      "dateCreated": "Mar 22, 2016 8:27:22 PM",
      "dateStarted": "Mar 22, 2016 8:27:48 PM",
      "dateFinished": "Mar 22, 2016 8:27:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%dep\nz.reset()\nz.addRepo(\"Spark Packages Repo\").url(\"http://dl.bintray.com/spark-packages/maven\")\nz.load(\"com.databricks:spark-csv_2.10:1.3.0\")\nz.load(\"org.apache.spark:spark-streaming-kafka_2.10:1.6.0\")",
      "dateUpdated": "Mar 22, 2016 8:28:03 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458674868094_-1879018923",
      "id": "20160322-202748_1310659044",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "res0: org.apache.zeppelin.spark.dep.Dependency \u003d org.apache.zeppelin.spark.dep.Dependency@12d9691f\n"
      },
      "dateCreated": "Mar 22, 2016 8:27:48 PM",
      "dateStarted": "Mar 22, 2016 8:28:03 PM",
      "dateFinished": "Mar 22, 2016 8:28:17 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\n\n/Users/hadoop/hadoop-1.2.1/bin/hadoop fs -mkdir data\n/Users/hadoop/hadoop-1.2.1/bin/hadoop fs -copyFromLocal /Users/hadoop/Downloads/SalesOrders2.csv data\n/Users/hadoop/hadoop-1.2.1/bin/hadoop fs -ls data\n",
      "dateUpdated": "Mar 22, 2016 8:36:03 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/sh"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458675202124_849723733",
      "id": "20160322-203322_1875538557",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "mkdir: cannot create directory data: File exists\ncopyFromLocal: Target data/SalesOrders2.csv already exists\nFound 3 items\n-rw-r--r--   1 hadoop supergroup     314001 2016-03-22 20:35 /user/hadoop/data/SalesOrders2.csv\n-rw-r--r--   1 hadoop supergroup   61626644 2016-03-21 12:13 /user/hadoop/data/europe-indicators.csv\n-rw-r--r--   1 hadoop supergroup       4821 2016-03-21 11:42 /user/hadoop/data/iris.csv\n"
      },
      "dateCreated": "Mar 22, 2016 8:33:22 PM",
      "dateStarted": "Mar 22, 2016 8:36:03 PM",
      "dateFinished": "Mar 22, 2016 8:36:10 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\nfilename \u003d \"hdfs:///user/hadoop/data/SalesOrders2.csv\"\nrawData \u003d sc.textFile(filename)\nheader \u003d rawData.first()\n\nrawData \u003d rawData.filter(lambda l: l !\u003d header)\nparsedData \u003d rawData.map(lambda r: r.split(\u0027\\t\u0027)).map(lambda fields: (float(fields[2]), str(fields[0])))\n\nfor l in parsedData.take(10):\n    print l\n",
      "dateUpdated": "Mar 22, 2016 9:17:11 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458674883055_1040871128",
      "id": "20160322-202803_219428680",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "(102.0, \u00272\u0027)\n(59.0, \u00272\u0027)\n(52.0, \u00272\u0027)\n(52.0, \u00272\u0027)\n(51.0, \u00272\u0027)\n(49.0, \u00272\u0027)\n(45.0, \u00272\u0027)\n(43.0, \u00272\u0027)\n(40.0, \u00272\u0027)\n(36.0, \u00272\u0027)\n"
      },
      "dateCreated": "Mar 22, 2016 8:28:03 PM",
      "dateStarted": "Mar 22, 2016 9:17:11 PM",
      "dateFinished": "Mar 22, 2016 9:17:11 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nfrom pyspark.mllib.clustering import KMeans\nfrom numpy import array\nfrom math import sqrt\n\n# train the model (cluster the data)\nclusters \u003d KMeans.train(parsedData, 3, maxIterations\u003d10, runs\u003d10, initializationMode\u003d\"random\")\n\n# build the centers of the cluster:\ncenters \u003d clusters.clusterCenters\n\nprint centers\n",
      "dateUpdated": "Mar 22, 2016 9:18:03 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458675542358_-961767679",
      "id": "20160322-203902_1685520375",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "[array([  45.18096208,  677.66607279]), array([  45.3051114 ,  408.81179554]), array([  45.09522574,  139.48780488])]\n"
      },
      "dateCreated": "Mar 22, 2016 8:39:02 PM",
      "dateStarted": "Mar 22, 2016 9:18:03 PM",
      "dateFinished": "Mar 22, 2016 9:18:04 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark \n\nfrom pyspark.mllib.clustering import KMeans\nfrom numpy import array\nfrom math import sqrt\n\n# Load and parse the data\ndata \u003d sc.textFile(\"file:///Users/hadoop/spark-1.3.1-bin-hadoop1/data/mllib/kmeans_data.txt\")\nparsedData \u003d data.map(lambda line: array([float(x) for x in line.split(\u0027 \u0027)]))\n\n# Build the model (cluster the data)\nclusters \u003d KMeans.train(parsedData, 2, maxIterations\u003d10,\n        runs\u003d10, initializationMode\u003d\"random\")\n\n# Evaluate clustering by computing Within Set Sum of Squared Errors\ndef error(point):\n    center \u003d clusters.centers[clusters.predict(point)]\n    return sqrt(sum([x**2 for x in (point - center)]))\n\nWSSSE \u003d parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)\nprint(\"Within Set Sum of Squared Error \u003d \" + str(WSSSE))",
      "dateUpdated": "Mar 22, 2016 9:06:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458675757015_-738138267",
      "id": "20160322-204237_1450358200",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "Within Set Sum of Squared Error \u003d 0.692820323028\n"
      },
      "dateCreated": "Mar 22, 2016 8:42:37 PM",
      "dateStarted": "Mar 22, 2016 9:06:30 PM",
      "dateFinished": "Mar 22, 2016 9:06:30 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1458677190454_57395455",
      "id": "20160322-210630_434506379",
      "dateCreated": "Mar 22, 2016 9:06:30 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Lab6 example kmeans",
  "id": "2BGCUHH8J",
  "angularObjects": {
    "2BCE6R8T2": [],
    "2BDMU83T5": [],
    "2BEMMQPJG": [],
    "2BDW72X9E": [],
    "2BF3AAW7U": [],
    "2BEJ4D5SJ": [],
    "2BF7MH2JM": [],
    "2BE1TRU6B": [],
    "2BE5CQ2W8": [],
    "2BFUXNJ9R": [],
    "2BCQ6J7ZP": [],
    "2BCWJF462": [],
    "2BFDNS2ZU": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}