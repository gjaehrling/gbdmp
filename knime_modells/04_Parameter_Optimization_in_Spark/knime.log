DEBUG	 MLlibKMeansNodeModel          	 MLlib k-Means : 0:50 : Removing all (0) views from model.
DEBUG	 MLlib k-Means                 	 MLlib k-Means : 0:50 : clean output ports.
DEBUG	 SparkSnippetNodeModel         	 Spark Snippet : 0:52 : Removing all (0) views from model.
DEBUG	 Spark Snippet                 	 Spark Snippet : 0:52 : clean output ports.
DEBUG	 GroupByNodeModel              	 GroupBy : 0:54 : Removing all (0) views from model.
DEBUG	 GroupBy                       	 GroupBy : 0:54 : clean output ports.
DEBUG	 Hive2SparkNodeModel           	 Hive to Spark : 0:49 : Removing all (0) views from model.
DEBUG	 Hive to Spark                 	 Hive to Spark : 0:49 : clean output ports.
DEBUG	 DBTableSelectorNodeModel      	 Database Table Selector : 0:43 : Removing all (0) views from model.
DEBUG	 Database Table Selector       	 Database Table Selector : 0:43 : clean output ports.
DEBUG	 LinReg2LearnerNodeModel       	 Linear Regression Learner : 0:56 : Removing all (0) views from model.
DEBUG	 Linear Regression Learner     	 Linear Regression Learner : 0:56 : clean output ports.
DEBUG	 JavaSnippetNodeModel          	 Java Snippet : 0:51 : Removing all (0) views from model.
DEBUG	 Java Snippet                  	 Java Snippet : 0:51 : clean output ports.
DEBUG	 HiveLoaderNodeModel           	 Hive Loader : 0:46 : Removing all (0) views from model.
DEBUG	 Hive Loader                   	 Hive Loader : 0:46 : clean output ports.
DEBUG	 DBSQLExecutorNodeModel        	 Database SQL Executor : 0:42 : Removing all (0) views from model.
DEBUG	 Database SQL Executor         	 Database SQL Executor : 0:42 : clean output ports.
DEBUG	 FileReaderNodeModel           	 File Reader : 0:55 : Removing all (0) views from model.
DEBUG	 File Reader                   	 File Reader : 0:55 : clean output ports.
DEBUG	 ConnectionInformationNodeModel	 SSH Connection : 0:48 : Removing all (0) views from model.
DEBUG	 SSH Connection                	 SSH Connection : 0:48 : clean output ports.
DEBUG	 FileReaderNodeModel           	 File Reader : 0:44 : Removing all (0) views from model.
DEBUG	 File Reader                   	 File Reader : 0:44 : clean output ports.
DEBUG	 HiveConnectorNodeModel        	 Hive Connector : 0:1 : Removing all (0) views from model.
DEBUG	 Hive Connector                	 Hive Connector : 0:1 : clean output ports.
DEBUG	 HiveConnectorNodeFactory      	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 DBSQLExecutorNodeFactory      	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 DBTableSelectorNodeFactory    	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 FileReaderNodeFactory         	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 HiveLoaderNodeFactory         	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 SSHConnectionInformationNodeFactory	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 Hive2SparkNodeFactory         	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 MLlibKMeansNodeFactory        	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 JavaSnippetNodeFactory        	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 SparkSnippetNodeFactory       	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 GroupByNodeFactory            	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 FileReaderNodeFactory         	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 LinReg2LearnerNodeFactory     	 Hive2Spark : 0 : Factory is already initialized. Nothing to do.
DEBUG	 File Reader                   	 File Reader : 0:55 : Configure succeeded. (File Reader)
DEBUG	 Java Snippet                  	 Java Snippet : 0:51 : Configure succeeded. (Java Snippet)
DEBUG	 Linear Regression Learner     	 Linear Regression Learner : 0:56 : Configure succeeded. (Linear Regression Learner)
WARN 	 Hive to Spark                 	 Hive to Spark : 0:49 : Spark context no longer available. Reset node.
WARN 	 GroupBy                       	 GroupBy : 0:54 : No grouping column included. Aggregate complete table.
DEBUG	 GroupByNodeModel              	 GroupBy : 0:54 : [sepal width->Sum false]
DEBUG	 GroupBy                       	 GroupBy : 0:54 : Configure succeeded. (GroupBy)
DEBUG	 Spark Snippet                 	 Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
WARN 	 MLlib k-Means                 	 MLlib k-Means : 0:50 : Spark context no longer available. Reset node.
DEBUG	 DBTableSelectorNodeFactory    	 zzz : 2 : Factory is already initialized. Nothing to do.
DEBUG	 DBTableSelectorNodeFactory    	 zzz(2) : 3 : Factory is already initialized. Nothing to do.
DEBUG	 MLlibKMeansNodeModel          	 MLlib k-Means : 0:50 : Removing all (0) views from model.
DEBUG	 MLlib k-Means                 	 MLlib k-Means : 0:50 : clean output ports.
DEBUG	 SparkSnippetNodeModel         	 Spark Snippet : 0:52 : Removing all (0) views from model.
DEBUG	 Spark Snippet                 	 Spark Snippet : 0:52 : clean output ports.
DEBUG	 GroupByNodeModel              	 GroupBy : 0:54 : Removing all (0) views from model.
DEBUG	 GroupBy                       	 GroupBy : 0:54 : clean output ports.
DEBUG	 Hive2SparkNodeModel           	 Hive to Spark : 0:49 : Removing all (0) views from model.
DEBUG	 Hive to Spark                 	 Hive to Spark : 0:49 : clean output ports.
DEBUG	 DBTableSelectorNodeModel      	 Database Table Selector : 0:43 : Removing all (0) views from model.
DEBUG	 Database Table Selector       	 Database Table Selector : 0:43 : clean output ports.
DEBUG	 LinReg2LearnerNodeModel       	 Linear Regression Learner : 0:56 : Removing all (0) views from model.
DEBUG	 Linear Regression Learner     	 Linear Regression Learner : 0:56 : clean output ports.
DEBUG	 JavaSnippetNodeModel          	 Java Snippet : 0:51 : Removing all (0) views from model.
DEBUG	 Java Snippet                  	 Java Snippet : 0:51 : clean output ports.
DEBUG	 HiveLoaderNodeModel           	 Hive Loader : 0:46 : Removing all (0) views from model.
DEBUG	 Hive Loader                   	 Hive Loader : 0:46 : clean output ports.
DEBUG	 DBSQLExecutorNodeModel        	 Database SQL Executor : 0:42 : Removing all (0) views from model.
DEBUG	 Database SQL Executor         	 Database SQL Executor : 0:42 : clean output ports.
DEBUG	 FileReaderNodeModel           	 File Reader : 0:55 : Removing all (0) views from model.
DEBUG	 File Reader                   	 File Reader : 0:55 : clean output ports.
DEBUG	 ConnectionInformationNodeModel	 SSH Connection : 0:48 : Removing all (0) views from model.
DEBUG	 SSH Connection                	 SSH Connection : 0:48 : clean output ports.
DEBUG	 FileReaderNodeModel           	 File Reader : 0:44 : Removing all (0) views from model.
DEBUG	 File Reader                   	 File Reader : 0:44 : clean output ports.
DEBUG	 HiveConnectorNodeModel        	 Hive Connector : 0:1 : Removing all (0) views from model.
DEBUG	 Hive Connector                	 Hive Connector : 0:1 : clean output ports.
DEBUG	 HiveConnectorNodeFactory      	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 DBSQLExecutorNodeFactory      	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 DBTableSelectorNodeFactory    	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 FileReaderNodeFactory         	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 HiveLoaderNodeFactory         	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 SSHConnectionInformationNodeFactory	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 Hive2SparkNodeFactory         	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 MLlibKMeansNodeFactory        	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 JavaSnippetNodeFactory        	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 SparkSnippetNodeFactory       	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 GroupByNodeFactory            	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 FileReaderNodeFactory         	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 LinReg2LearnerNodeFactory     	 Hive2Spark : 2 : Factory is already initialized. Nothing to do.
DEBUG	 File Reader                   	 File Reader : 2:55 : Configure succeeded. (File Reader)
DEBUG	 Java Snippet                  	 Java Snippet : 2:51 : Configure succeeded. (Java Snippet)
DEBUG	 Linear Regression Learner     	 Linear Regression Learner : 2:56 : Configure succeeded. (Linear Regression Learner)
DEBUG	 Hive to Spark                 	 Hive to Spark : 2:49 : Loading model internals failed: Failed to load named rdd
java.io.IOException: Failed to load named rdd
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:200)
	at org.knime.core.node.Node.loadDataAndInternals(Node.java:465)
	at org.knime.core.node.Node.load(Node.java:326)
	at org.knime.core.node.FileNodePersistor.load(FileNodePersistor.java:1037)
	at org.knime.core.node.workflow.FileNativeNodeContainerPersistor.loadNCAndWashModelSettings(FileNativeNodeContainerPersistor.java:272)
	at org.knime.core.node.workflow.FileSingleNodeContainerPersistor.loadNodeContainer(FileSingleNodeContainerPersistor.java:270)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7535)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7553)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7379)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7304)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7277)
	at org.knime.core.node.workflow.WorkflowManager.loadProject(WorkflowManager.java:7115)
	at org.knime.workbench.editor2.LoadWorkflowRunnable.run(LoadWorkflowRunnable.java:154)
	at org.eclipse.jface.operation.ModalContext$ModalContextThread.run(ModalContext.java:121)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1300)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.glassfish.jersey.client.HttpUrlConnector._apply(HttpUrlConnector.java:335)
	at org.glassfish.jersey.client.HttpUrlConnector.apply(HttpUrlConnector.java:242)
	at org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:245)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:671)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:668)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:228)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:444)
	at org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:668)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:402)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.get(JerseyInvocation.java:302)
	at com.knime.bigdata.spark.jobserver.client.WsRsRestClient.toJSONArray(WsRsRestClient.java:125)
	at com.knime.bigdata.spark.jobserver.client.RestClient.toJSONArray(RestClient.java:80)
	at com.knime.bigdata.spark.jobserver.client.KnimeContext.sparkContextExists(KnimeContext.java:70)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:193)
	... 15 more
DEBUG	 DataType                      	 GroupBy : 2:54 : DateAndTimeValue is the preferred value class of cell implementation DateAndTimeCell, made sanity check
DEBUG	 DataType                      	 GroupBy : 2:54 : BitVectorValue is the preferred value class of cell implementation DenseBitVectorCell, made sanity check
WARN 	 GroupBy                       	 GroupBy : 2:54 : No grouping column included. Aggregate complete table.
DEBUG	 GroupByNodeModel              	 GroupBy : 2:54 : [sepal width->Sum false]
DEBUG	 GroupBy                       	 GroupBy : 2:54 : Configure succeeded. (GroupBy)
DEBUG	 Spark Snippet                 	 Spark Snippet : 2:52 : Configure succeeded. (Spark Snippet)
DEBUG	 MLlib k-Means                 	 MLlib k-Means : 2:50 : Loading model internals failed: Failed to load named rdd
java.io.IOException: Failed to load named rdd
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:200)
	at org.knime.core.node.Node.loadDataAndInternals(Node.java:465)
	at org.knime.core.node.Node.load(Node.java:326)
	at org.knime.core.node.FileNodePersistor.load(FileNodePersistor.java:1037)
	at org.knime.core.node.workflow.FileNativeNodeContainerPersistor.loadNCAndWashModelSettings(FileNativeNodeContainerPersistor.java:272)
	at org.knime.core.node.workflow.FileSingleNodeContainerPersistor.loadNodeContainer(FileSingleNodeContainerPersistor.java:270)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7535)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7553)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7379)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7304)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7277)
	at org.knime.core.node.workflow.WorkflowManager.loadProject(WorkflowManager.java:7115)
	at org.knime.workbench.editor2.LoadWorkflowRunnable.run(LoadWorkflowRunnable.java:154)
	at org.eclipse.jface.operation.ModalContext$ModalContextThread.run(ModalContext.java:121)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1300)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.glassfish.jersey.client.HttpUrlConnector._apply(HttpUrlConnector.java:335)
	at org.glassfish.jersey.client.HttpUrlConnector.apply(HttpUrlConnector.java:242)
	at org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:245)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:671)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:668)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:228)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:444)
	at org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:668)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:402)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.get(JerseyInvocation.java:302)
	at com.knime.bigdata.spark.jobserver.client.WsRsRestClient.toJSONArray(WsRsRestClient.java:125)
	at com.knime.bigdata.spark.jobserver.client.RestClient.toJSONArray(RestClient.java:80)
	at com.knime.bigdata.spark.jobserver.client.KnimeContext.sparkContextExists(KnimeContext.java:70)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:193)
	... 15 more
DEBUG	 Linear Regression Learner     	 Linear Regression Learner : 2:56 : reset
DEBUG	 Linear Regression Learner     	 Linear Regression Learner : 2:56 : clean output ports.
DEBUG	 Linear Regression Learner     	 Linear Regression Learner : 2:56 : Configure succeeded. (Linear Regression Learner)
DEBUG	 WorkflowManager               	 File Reader : 2:55 : File Reader 2:55 doBeforePreExecution
DEBUG	 NodeContainer                 	 File Reader : 2:55 : File Reader 2:55 has new state: PREEXECUTE
DEBUG	 WorkflowManager               	 File Reader : 2:55 : File Reader 2:55 doBeforeExecution
DEBUG	 NodeContainer                 	 File Reader : 2:55 : File Reader 2:55 has new state: EXECUTING
DEBUG	 WorkflowFileStoreHandlerRepository	 File Reader : 2:55 : Adding handler f82d39cd-0e14-45fa-beda-9d92c1d820a5 (File Reader 2:55: <no directory>) - 1 in total
DEBUG	 LocalNodeExecutionJob         	 File Reader : 2:55 : File Reader 2:55 Start execute
INFO 	 FileReaderNodeModel           	 File Reader : 2:55 : Preparing to read from 'file:/C:/DATA/KNIME/benchmarks/iris/data.all'.
DEBUG	 MemoryObjectTracker           	 File Reader : 2:55 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (1 in total)
INFO 	 LocalNodeExecutionJob         	 File Reader : 2:55 : File Reader 2:55 End execute (0 secs)
DEBUG	 WorkflowManager               	 File Reader : 2:55 : File Reader 2:55 doBeforePostExecution
DEBUG	 NodeContainer                 	 File Reader : 2:55 : File Reader 2:55 has new state: POSTEXECUTE
DEBUG	 WorkflowManager               	 File Reader : 2:55 : File Reader 2:55 doAfterExecute - success
DEBUG	 NodeContainer                 	 File Reader : 2:55 : File Reader 2:55 has new state: EXECUTED
DEBUG	 Linear Regression Learner     	 Linear Regression Learner : 2:56 : Configure succeeded. (Linear Regression Learner)
DEBUG	 NodeContainer                 	 File Reader : 2:55 : Linear Regression Learner 2:56 has new state: CONFIGURED_QUEUED
DEBUG	 WorkflowManager               	 Linear Regression Learner : 2:56 : Linear Regression Learner 2:56 doBeforePreExecution
DEBUG	 NodeContainer                 	 Linear Regression Learner : 2:56 : Linear Regression Learner 2:56 has new state: PREEXECUTE
DEBUG	 WorkflowManager               	 Linear Regression Learner : 2:56 : Linear Regression Learner 2:56 doBeforeExecution
DEBUG	 NodeContainer                 	 Linear Regression Learner : 2:56 : Linear Regression Learner 2:56 has new state: EXECUTING
DEBUG	 WorkflowFileStoreHandlerRepository	 Linear Regression Learner : 2:56 : Adding handler 409c2be8-fa61-408e-bc7b-d7815063a4cd (Linear Regression Learner 2:56: <no directory>) - 2 in total
DEBUG	 LocalNodeExecutionJob         	 Linear Regression Learner : 2:56 : Linear Regression Learner 2:56 Start execute
DEBUG	 DataType                      	 Linear Regression Learner : 2:56 : PMMLValue is the preferred value class of cell implementation PMMLCell, made sanity check
DEBUG	 DataType                      	 Linear Regression Learner : 2:56 : PMMLValue is the preferred value class of cell implementation PMMLCell, made sanity check
DEBUG	 DataType                      	 Linear Regression Learner : 2:56 : XMLValue is the preferred value class of cell implementation XMLCell, made sanity check
DEBUG	 DataType                      	 Linear Regression Learner : 2:56 : XMLValue is the preferred value class of cell implementation XMLCell, made sanity check
DEBUG	 MemoryObjectTracker           	 Linear Regression Learner : 2:56 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (2 in total)
INFO 	 LocalNodeExecutionJob         	 Linear Regression Learner : 2:56 : Linear Regression Learner 2:56 End execute (0 secs)
DEBUG	 WorkflowManager               	 Linear Regression Learner : 2:56 : Linear Regression Learner 2:56 doBeforePostExecution
DEBUG	 NodeContainer                 	 Linear Regression Learner : 2:56 : Linear Regression Learner 2:56 has new state: POSTEXECUTE
DEBUG	 WorkflowManager               	 Linear Regression Learner : 2:56 : Linear Regression Learner 2:56 doAfterExecute - success
DEBUG	 NodeContainer                 	 Linear Regression Learner : 2:56 : Linear Regression Learner 2:56 has new state: EXECUTED
DEBUG	 NodeContainer                 	 Linear Regression Learner : 2:56 : Hive2Spark 2 has new state: CONFIGURED
DEBUG	 NodeContainer                 	 ROOT  has new state: IDLE
DEBUG	 WorkflowManager               	 Loading workflow from "C:\DEVELOPMENT\runtime-workspaces\dev\zzz" (version "V2100" with loader class "FileWorkflowPersistor")
DEBUG	 WorkflowManager               	 Created subworkflow 0
DEBUG	 DBTableSelectorNodeFactory    	 zzz : 0 : Factory is already initialized. Nothing to do.
DEBUG	 NodeContainer                 	 zzz 0 has new state: EXECUTED
DEBUG	 NodeContainer                 	 zzz 0 has new state: CONFIGURED
DEBUG	 NodeContainer                 	 zzz 0 has new state: IDLE
DEBUG	 WorkflowManager               	 Added new connection from node 0:1(1) to node 0:2(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:78(1) to node 0:63(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:63(1) to node 0:65(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:2(1) to node 0:78(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:79(2) to node 0:82(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:79(1) to node 0:81(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:79(1) to node 0:80(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:69(1) to node 0:72(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:65(1) to node 0:67(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:2(1) to node 0:63(2)
DEBUG	 WorkflowManager               	 Added new connection from node 0:67(1) to node 0:69(1)
DEBUG	 WorkflowManager               	 Loaded workflow from "C:\DEVELOPMENT\runtime-workspaces\dev\zzz"  with no errors
DEBUG	 WorkflowManager               	 Removing project "zzz 0"
DEBUG	 WorkflowManager               	 Project "zzz 0" removed (2 remaining)
DEBUG	 WorkflowManager               	 Loading workflow from "C:\DEVELOPMENT\runtime-workspaces\dev\zzz" (version "V2100" with loader class "FileWorkflowPersistor")
DEBUG	 WorkflowManager               	 Created subworkflow 0
DEBUG	 DBTableSelectorNodeFactory    	 zzz : 0 : Factory is already initialized. Nothing to do.
DEBUG	 NodeContainer                 	 zzz 0 has new state: EXECUTED
DEBUG	 NodeContainer                 	 zzz 0 has new state: CONFIGURED
DEBUG	 NodeContainer                 	 zzz 0 has new state: IDLE
DEBUG	 WorkflowManager               	 Added new connection from node 0:1(1) to node 0:2(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:78(1) to node 0:63(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:63(1) to node 0:65(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:2(1) to node 0:78(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:79(2) to node 0:82(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:79(1) to node 0:81(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:79(1) to node 0:80(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:69(1) to node 0:72(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:65(1) to node 0:67(1)
DEBUG	 WorkflowManager               	 Added new connection from node 0:2(1) to node 0:63(2)
DEBUG	 WorkflowManager               	 Added new connection from node 0:67(1) to node 0:69(1)
DEBUG	 WorkflowManager               	 Loaded workflow from "C:\DEVELOPMENT\runtime-workspaces\dev\zzz"  with no errors
DEBUG	 NodeContainer                 	 Setting dirty flag on Column Aggregator 0:80
DEBUG	 NodeContainer                 	 Setting dirty flag on zzz 0
DEBUG	 NodeContainer                 	 Column Aggregator 0:80 has new state: UNCONFIGURED_MARKEDFOREXEC
DEBUG	 NodeContainer                 	 Column Aggregator 0:80 has new state: IDLE
DEBUG	 NodeContainer                 	 Setting dirty flag on Group Loop Start 0:82
DEBUG	 NodeContainer                 	 Group Loop Start 0:82 has new state: CONFIGURED_MARKEDFOREXEC
DEBUG	 NodeContainer                 	 Group Loop Start 0:82 has new state: CONFIGURED_QUEUED
DEBUG	 NodeContainer                 	 zzz 0 has new state: EXECUTING
DEBUG	 NodeContainer                 	 ROOT  has new state: EXECUTING
DEBUG	 NodeContainer                 	 Setting dirty flag on Database Connection Table Reader 0:72
DEBUG	 NodeContainer                 	 Database Connection Table Reader 0:72 has new state: CONFIGURED_MARKEDFOREXEC
DEBUG	 NodeContainer                 	 Database Connection Table Reader 0:72 has new state: CONFIGURED_QUEUED
DEBUG	 WorkflowManager               	 Database Connection Table Reader : 0:72 : Database Connection Table Reader 0:72 doBeforePreExecution
DEBUG	 NodeContainer                 	 Database Connection Table Reader : 0:72 : Database Connection Table Reader 0:72 has new state: PREEXECUTE
DEBUG	 WorkflowManager               	 Database Connection Table Reader : 0:72 : Database Connection Table Reader 0:72 doBeforeExecution
DEBUG	 NodeContainer                 	 Database Connection Table Reader : 0:72 : Database Connection Table Reader 0:72 has new state: EXECUTING
DEBUG	 WorkflowFileStoreHandlerRepository	 Database Connection Table Reader : 0:72 : Adding handler 10be19fe-5707-4ee3-bb21-4a4e7c4ce69c (Database Connection Table Reader 0:72: <no directory>) - 1 in total
DEBUG	 WorkflowManager               	 Group Loop Start : 0:82 : Group Loop Start 0:82 doBeforePreExecution
DEBUG	 LocalNodeExecutionJob         	 Database Connection Table Reader : 0:72 : Database Connection Table Reader 0:72 Start execute
DEBUG	 NodeContainer                 	 Group Loop Start : 0:82 : Group Loop Start 0:82 has new state: PREEXECUTE
DEBUG	 WorkflowManager               	 Group Loop Start : 0:82 : Group Loop Start 0:82 doBeforeExecution
DEBUG	 NodeContainer                 	 Group Loop Start : 0:82 : Group Loop Start 0:82 has new state: EXECUTING
DEBUG	 WorkflowFileStoreHandlerRepository	 Group Loop Start : 0:82 : Adding handler af30b15b-ad63-45ad-97f0-a06ff9b1971d (Group Loop Start 0:82: <no directory>) - 2 in total
DEBUG	 LocalNodeExecutionJob         	 Group Loop Start : 0:82 : Group Loop Start 0:82 Start execute
DEBUG	 WorkflowManager               	 Database Connection Table Reader : 0:72 : Database Connection Table Reader 0:72 doBeforePostExecution
DEBUG	 NodeContainer                 	 Database Connection Table Reader : 0:72 : Database Connection Table Reader 0:72 has new state: POSTEXECUTE
DEBUG	 WorkflowManager               	 Database Connection Table Reader : 0:72 : Database Connection Table Reader 0:72 doAfterExecute - failure
DEBUG	 WorkflowFileStoreHandlerRepository	 Database Connection Table Reader : 0:72 : Removing handler 10be19fe-5707-4ee3-bb21-4a4e7c4ce69c (Database Connection Table Reader 0:72: <no directory>) - 1 remaining
DEBUG	 NodeContainer                 	 Database Connection Table Reader : 0:72 : Database Connection Table Reader 0:72 has new state: IDLE
DEBUG	 NodeContainer                 	 Database Connection Table Reader : 0:72 : Database Connection Table Reader 0:72 has new state: CONFIGURED
DEBUG	 MemoryObjectTracker           	 Group Loop Start : 0:82 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (3 in total)
DEBUG	 MemoryObjectTracker           	 Group Loop Start : 0:82 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (4 in total)
DEBUG	 MemoryObjectTracker           	 Group Loop Start : 0:82 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (5 in total)
INFO 	 LocalNodeExecutionJob         	 Group Loop Start : 0:82 : Group Loop Start 0:82 End execute (0 secs)
DEBUG	 WorkflowManager               	 Group Loop Start : 0:82 : Group Loop Start 0:82 doBeforePostExecution
DEBUG	 NodeContainer                 	 Group Loop Start : 0:82 : Group Loop Start 0:82 has new state: POSTEXECUTE
DEBUG	 WorkflowManager               	 Group Loop Start : 0:82 : Group Loop Start 0:82 doAfterExecute - success
DEBUG	 NodeContainer                 	 Group Loop Start : 0:82 : Group Loop Start 0:82 has new state: EXECUTED
DEBUG	 NodeContainer                 	 Group Loop Start : 0:82 : zzz 0 has new state: IDLE
DEBUG	 NodeContainer                 	 ROOT  has new state: IDLE
DEBUG	 WorkflowManager               	 Loading workflow from "C:\DEVELOPMENT\runtime-workspaces\dev\zzz(2)" (version "V2100" with loader class "FileWorkflowPersistor")
DEBUG	 WorkflowManager               	 Created subworkflow 3
DEBUG	 DBTableSelectorNodeFactory    	 zzz(2) : 3 : Factory is already initialized. Nothing to do.
DEBUG	 NodeContainer                 	 zzz(2) 3 has new state: EXECUTED
DEBUG	 NodeContainer                 	 zzz(2) 3 has new state: CONFIGURED
DEBUG	 NodeContainer                 	 zzz(2) 3 has new state: IDLE
DEBUG	 WorkflowManager               	 Added new connection from node 3:1(1) to node 3:2(1)
DEBUG	 WorkflowManager               	 Added new connection from node 3:78(1) to node 3:63(1)
DEBUG	 WorkflowManager               	 Added new connection from node 3:63(1) to node 3:65(1)
DEBUG	 WorkflowManager               	 Added new connection from node 3:2(1) to node 3:78(1)
DEBUG	 WorkflowManager               	 Added new connection from node 3:79(2) to node 3:82(1)
DEBUG	 WorkflowManager               	 Added new connection from node 3:79(1) to node 3:81(1)
DEBUG	 WorkflowManager               	 Added new connection from node 3:79(1) to node 3:80(1)
DEBUG	 WorkflowManager               	 Added new connection from node 3:69(1) to node 3:72(1)
DEBUG	 WorkflowManager               	 Added new connection from node 3:65(1) to node 3:67(1)
DEBUG	 WorkflowManager               	 Added new connection from node 3:2(1) to node 3:63(2)
DEBUG	 WorkflowManager               	 Added new connection from node 3:67(1) to node 3:69(1)
DEBUG	 WorkflowManager               	 Loaded workflow from "C:\DEVELOPMENT\runtime-workspaces\dev\zzz(2)"  with no errors
DEBUG	 NodeContainer                 	 Setting dirty flag on Data Generator 3:79
DEBUG	 NodeContainer                 	 Setting dirty flag on zzz(2) 3
DEBUG	 NodeContainer                 	 Data Generator 3:79 has new state: CONFIGURED_MARKEDFOREXEC
DEBUG	 NodeContainer                 	 Data Generator 3:79 has new state: CONFIGURED_QUEUED
DEBUG	 NodeContainer                 	 Setting dirty flag on Column Aggregator 3:80
DEBUG	 NodeContainer                 	 Column Aggregator 3:80 has new state: UNCONFIGURED_MARKEDFOREXEC
DEBUG	 NodeContainer                 	 zzz(2) 3 has new state: EXECUTING
DEBUG	 NodeContainer                 	 ROOT  has new state: EXECUTING
DEBUG	 NodeContainer                 	 Setting dirty flag on Group Loop Start 3:82
DEBUG	 NodeContainer                 	 Group Loop Start 3:82 has new state: CONFIGURED_MARKEDFOREXEC
DEBUG	 NodeContainer                 	 Setting dirty flag on Column Filter 3:81
DEBUG	 NodeContainer                 	 Column Filter 3:81 has new state: CONFIGURED_MARKEDFOREXEC
DEBUG	 NodeContainer                 	 Setting dirty flag on Database Connection Table Reader 3:72
DEBUG	 NodeContainer                 	 Database Connection Table Reader 3:72 has new state: CONFIGURED_MARKEDFOREXEC
DEBUG	 NodeContainer                 	 Database Connection Table Reader 3:72 has new state: CONFIGURED_QUEUED
DEBUG	 WorkflowManager               	 Database Connection Table Reader : 3:72 : Database Connection Table Reader 3:72 doBeforePreExecution
DEBUG	 NodeContainer                 	 Database Connection Table Reader : 3:72 : Database Connection Table Reader 3:72 has new state: PREEXECUTE
DEBUG	 WorkflowManager               	 Database Connection Table Reader : 3:72 : Database Connection Table Reader 3:72 doBeforeExecution
DEBUG	 NodeContainer                 	 Database Connection Table Reader : 3:72 : Database Connection Table Reader 3:72 has new state: EXECUTING
DEBUG	 WorkflowFileStoreHandlerRepository	 Database Connection Table Reader : 3:72 : Adding handler f8dd94d6-595d-4d04-8e75-f9154896f464 (Database Connection Table Reader 3:72: <no directory>) - 1 in total
DEBUG	 WorkflowManager               	 Data Generator : 3:79 : Data Generator 3:79 doBeforePreExecution
DEBUG	 LocalNodeExecutionJob         	 Database Connection Table Reader : 3:72 : Database Connection Table Reader 3:72 Start execute
DEBUG	 NodeContainer                 	 Data Generator : 3:79 : Data Generator 3:79 has new state: PREEXECUTE
DEBUG	 WorkflowManager               	 Data Generator : 3:79 : Data Generator 3:79 doBeforeExecution
DEBUG	 NodeContainer                 	 Data Generator : 3:79 : Data Generator 3:79 has new state: EXECUTING
DEBUG	 WorkflowFileStoreHandlerRepository	 Data Generator : 3:79 : Adding handler 81fab047-de63-4eb6-b4c6-57942510416e (Data Generator 3:79: <no directory>) - 2 in total
DEBUG	 LocalNodeExecutionJob         	 Data Generator : 3:79 : Data Generator 3:79 Start execute
DEBUG	 MemoryObjectTracker           	 Data Generator : 3:79 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (6 in total)
DEBUG	 MemoryObjectTracker           	 Data Generator : 3:79 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (7 in total)
DEBUG	 WorkflowManager               	 Database Connection Table Reader : 3:72 : Database Connection Table Reader 3:72 doBeforePostExecution
DEBUG	 NodeContainer                 	 Database Connection Table Reader : 3:72 : Database Connection Table Reader 3:72 has new state: POSTEXECUTE
DEBUG	 WorkflowManager               	 Database Connection Table Reader : 3:72 : Database Connection Table Reader 3:72 doAfterExecute - failure
DEBUG	 WorkflowFileStoreHandlerRepository	 Database Connection Table Reader : 3:72 : Removing handler f8dd94d6-595d-4d04-8e75-f9154896f464 (Database Connection Table Reader 3:72: <no directory>) - 1 remaining
DEBUG	 NodeContainer                 	 Database Connection Table Reader : 3:72 : Database Connection Table Reader 3:72 has new state: IDLE
DEBUG	 NodeContainer                 	 Database Connection Table Reader : 3:72 : Database Connection Table Reader 3:72 has new state: CONFIGURED
INFO 	 LocalNodeExecutionJob         	 Data Generator : 3:79 : Data Generator 3:79 End execute (0 secs)
DEBUG	 WorkflowManager               	 Data Generator : 3:79 : Data Generator 3:79 doBeforePostExecution
DEBUG	 NodeContainer                 	 Data Generator : 3:79 : Data Generator 3:79 has new state: POSTEXECUTE
DEBUG	 WorkflowManager               	 Data Generator : 3:79 : Data Generator 3:79 doAfterExecute - success
DEBUG	 NodeContainer                 	 Data Generator : 3:79 : Data Generator 3:79 has new state: EXECUTED
DEBUG	 NodeContainer                 	 Data Generator : 3:79 : Group Loop Start 3:82 has new state: CONFIGURED_QUEUED
DEBUG	 NodeContainer                 	 Data Generator : 3:79 : Column Filter 3:81 has new state: CONFIGURED_QUEUED
DEBUG	 NodeContainer                 	 Data Generator : 3:79 : Column Aggregator 3:80 has new state: IDLE
DEBUG	 WorkflowManager               	 Column Filter : 3:81 : Column Filter 3:81 doBeforePreExecution
DEBUG	 NodeContainer                 	 Column Filter : 3:81 : Column Filter 3:81 has new state: PREEXECUTE
DEBUG	 WorkflowManager               	 Column Filter : 3:81 : Column Filter 3:81 doBeforeExecution
DEBUG	 NodeContainer                 	 Column Filter : 3:81 : Column Filter 3:81 has new state: EXECUTING
DEBUG	 WorkflowFileStoreHandlerRepository	 Column Filter : 3:81 : Adding handler ed88e5e9-f173-45d1-9570-68cfd7d30a65 (Column Filter 3:81: <no directory>) - 2 in total
DEBUG	 LocalNodeExecutionJob         	 Column Filter : 3:81 : Column Filter 3:81 Start execute
DEBUG	 WorkflowManager               	 Group Loop Start : 3:82 : Group Loop Start 3:82 doBeforePreExecution
DEBUG	 NodeContainer                 	 Group Loop Start : 3:82 : Group Loop Start 3:82 has new state: PREEXECUTE
INFO 	 LocalNodeExecutionJob         	 Column Filter : 3:81 : Column Filter 3:81 End execute (0 secs)
DEBUG	 WorkflowManager               	 Group Loop Start : 3:82 : Group Loop Start 3:82 doBeforeExecution
DEBUG	 NodeContainer                 	 Group Loop Start : 3:82 : Group Loop Start 3:82 has new state: EXECUTING
DEBUG	 WorkflowFileStoreHandlerRepository	 Group Loop Start : 3:82 : Adding handler 7819d7f9-f9e8-41cf-b67d-f9559d15ed9a (Group Loop Start 3:82: <no directory>) - 3 in total
DEBUG	 LocalNodeExecutionJob         	 Group Loop Start : 3:82 : Group Loop Start 3:82 Start execute
DEBUG	 LocalNodeExecutionJob         	 Group Loop Start : 3:82 : Group Loop Start 3:82 Start execute
Column Filter : 3:81 : Column Filter 3:81 doBeforePostExecution
DEBUG	 NodeContainer                 	 Column Filter : 3:81 : Column Filter 3:81 has new state: POSTEXECUTE
DEBUG	 WorkflowManager               	 Column Filter : 3:81 : Column Filter 3:81 doAfterExecute - success
DEBUG	 NodeContainer                 	 Group Loop Start : 3:82 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (8 in total)
DEBUG	 NodeContainer                 	 Group Loop Start : 3:82 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (8 in total)
Column Filter : 3:81 : Column Filter 3:81 has new state: EXECUTED
DEBUG	 MemoryObjectTracker           	 Group Loop Start : 3:82 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (9 in total)
INFO 	 LocalNodeExecutionJob         	 Group Loop Start : 3:82 : Group Loop Start 3:82 End execute (0 secs)
DEBUG	 WorkflowManager               	 Group Loop Start : 3:82 : Group Loop Start 3:82 doBeforePostExecution
DEBUG	 NodeContainer                 	 Group Loop Start : 3:82 : Group Loop Start 3:82 has new state: POSTEXECUTE
DEBUG	 WorkflowManager               	 Group Loop Start : 3:82 : Group Loop Start 3:82 doAfterExecute - success
DEBUG	 NodeContainer                 	 Group Loop Start : 3:82 : Group Loop Start 3:82 has new state: EXECUTED
DEBUG	 NodeContainer                 	 Group Loop Start : 3:82 : zzz(2) 3 has new state: IDLE
DEBUG	 NodeContainer                 	 ROOT  has new state: IDLE
DEBUG	 WorkflowManager               	 Loading workflow from "C:\DEVELOPMENT\runtime-workspaces\dev\01502_documentQueries" (version "V260" with loader class "FileWorkflowPersistor")
DEBUG	 WorkflowManager               	 Created subworkflow 4
DEBUG	 NodeContainer                 	 01502_documentQueries 4 has new state: EXECUTED
DEBUG	 NodeContainer                 	 01502_documentQueries 4 has new state: CONFIGURED
DEBUG	 WorkflowManager               	 Added new connection from node 4:18(1) to node 4:17(2)
DEBUG	 WorkflowManager               	 Added new connection from node 4:2(1) to node 4:3(1)
DEBUG	 WorkflowManager               	 Added new connection from node 4:8(1) to node 4:15(1)
DEBUG	 WorkflowManager               	 Added new connection from node 4:2(1) to node 4:8(1)
DEBUG	 WorkflowManager               	 Added new connection from node 4:2(1) to node 4:11(1)
DEBUG	 WorkflowManager               	 Added new connection from node 4:2(1) to node 4:12(1)
DEBUG	 WorkflowManager               	 Added new connection from node 4:14(1) to node 4:16(1)
DEBUG	 WorkflowManager               	 Added new connection from node 4:14(1) to node 4:2(1)
DEBUG	 WorkflowManager               	 Added new connection from node 4:14(1) to node 4:17(1)
DEBUG	 DataType                      	 Table Reader : 4:14 : DocumentValue is the preferred value class of cell implementation DocumentBlobCell, made sanity check
DEBUG	 MemoryObjectTracker           	 Document Viewer : 4:16 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (10 in total)
DEBUG	 NodeContainer                 	 Setting dirty flag on Table Indexer 4:2
DEBUG	 NodeContainer                 	 Setting dirty flag on 01502_documentQueries 4
DEBUG	 NodeContainer                 	 Table Indexer 4:2 has new state: IDLE
DEBUG	 DataType                      	 Table Indexer : 4:2 : BooleanValue is the preferred value class of cell implementation BooleanCell, made sanity check
DEBUG	 DataType                      	 Table Indexer : 4:2 : Class "DataCell" doesn't have a default value class (it does not implement a static method "getPreferredValueClass()"). Returning null
DEBUG	 DataType                      	 Table Indexer : 4:2 : DocumentValue is the preferred value class of cell implementation DocumentCell, made sanity check
DEBUG	 DataType                      	 Table Indexer : 4:2 : GraphValue is the preferred value class of cell implementation GraphCell, made sanity check
DEBUG	 NodeContainer                 	 Table Indexer 4:2 has new state: CONFIGURED
DEBUG	 DataType                      	 Dictionary tagger : 4:17 : DocumentValue is the preferred value class of cell implementation DocumentBufferedFileStoreCell, made sanity check
DEBUG	 NodeContainer                 	 Setting dirty flag on Index Query 4:3
DEBUG	 NodeContainer                 	 Index Query 4:3 has new state: IDLE
DEBUG	 NodeContainer                 	 Index Query 4:3 has new state: CONFIGURED
DEBUG	 NodeContainer                 	 Setting dirty flag on Index Query 4:8
DEBUG	 NodeContainer                 	 Index Query 4:8 has new state: IDLE
DEBUG	 NodeContainer                 	 Index Query 4:8 has new state: CONFIGURED
DEBUG	 NodeContainer                 	 Setting dirty flag on Index Query 4:11
DEBUG	 NodeContainer                 	 Index Query 4:11 has new state: IDLE
DEBUG	 NodeContainer                 	 Index Query 4:11 has new state: CONFIGURED
DEBUG	 NodeContainer                 	 Setting dirty flag on Index Query 4:12
DEBUG	 NodeContainer                 	 Index Query 4:12 has new state: IDLE
DEBUG	 NodeContainer                 	 Index Query 4:12 has new state: CONFIGURED
DEBUG	 MemoryObjectTracker           	 Document Viewer : 4:15 : Adding org.knime.core.data.container.Buffer$BufferMemoryReleasable (11 in total)
DEBUG	 NodeContainer                 	 Setting dirty flag on Document Viewer 4:15
DEBUG	 NodeContainer                 	 Document Viewer 4:15 has new state: IDLE
DEBUG	 NodeContainer                 	 Document Viewer 4:15 has new state: CONFIGURED
DEBUG	 WorkflowManager               	 Loaded workflow from "C:\DEVELOPMENT\runtime-workspaces\dev\01502_documentQueries"  with errors during data load. Problems were fixed but not saved!
DEBUG	 WorkflowManager               	 Removing project "Hive2Spark 2"
DEBUG	 MLlibKMeansNodeModel          	 MLlib k-Means : 2:50 : Removing all (0) views from model.
DEBUG	 MLlib k-Means                 	 MLlib k-Means : 2:50 : clean output ports.
DEBUG	 SparkSnippetNodeModel         	 Spark Snippet : 2:52 : Removing all (0) views from model.
DEBUG	 Spark Snippet                 	 Spark Snippet : 2:52 : clean output ports.
DEBUG	 GroupByNodeModel              	 GroupBy : 2:54 : Removing all (0) views from model.
DEBUG	 GroupBy                       	 GroupBy : 2:54 : clean output ports.
DEBUG	 Hive2SparkNodeModel           	 Hive to Spark : 2:49 : Removing all (0) views from model.
DEBUG	 Hive to Spark                 	 Hive to Spark : 2:49 : clean output ports.
DEBUG	 DBTableSelectorNodeModel      	 Database Table Selector : 2:43 : Removing all (0) views from model.
DEBUG	 Database Table Selector       	 Database Table Selector : 2:43 : clean output ports.
DEBUG	 WorkflowFileStoreHandlerRepository	 Linear Regression Learner : 2:56 : Removing handler 409c2be8-fa61-408e-bc7b-d7815063a4cd (Linear Regression Learner 2:56: <no directory>) - 1 remaining
DEBUG	 LinReg2LearnerNodeModel       	 Linear Regression Learner : 2:56 : Removing all (0) views from model.
DEBUG	 Linear Regression Learner     	 Linear Regression Learner : 2:56 : clean output ports.
DEBUG	 MemoryObjectTracker           	 Linear Regression Learner : 2:56 : Removing org.knime.core.data.container.Buffer$BufferMemoryReleasable (10 remaining)
DEBUG	 JavaSnippetNodeModel          	 Java Snippet : 2:51 : Removing all (0) views from model.
DEBUG	 Java Snippet                  	 Java Snippet : 2:51 : clean output ports.
DEBUG	 HiveLoaderNodeModel           	 Hive Loader : 2:46 : Removing all (0) views from model.
DEBUG	 Hive Loader                   	 Hive Loader : 2:46 : clean output ports.
DEBUG	 DBSQLExecutorNodeModel        	 Database SQL Executor : 2:42 : Removing all (0) views from model.
DEBUG	 Database SQL Executor         	 Database SQL Executor : 2:42 : clean output ports.
DEBUG	 WorkflowFileStoreHandlerRepository	 File Reader : 2:55 : Removing handler f82d39cd-0e14-45fa-beda-9d92c1d820a5 (File Reader 2:55: <no directory>) - 0 remaining
DEBUG	 FileReaderNodeModel           	 File Reader : 2:55 : Removing all (0) views from model.
DEBUG	 File Reader                   	 File Reader : 2:55 : clean output ports.
DEBUG	 MemoryObjectTracker           	 File Reader : 2:55 : Removing org.knime.core.data.container.Buffer$BufferMemoryReleasable (9 remaining)
DEBUG	 ConnectionInformationNodeModel	 SSH Connection : 2:48 : Removing all (0) views from model.
DEBUG	 SSH Connection                	 SSH Connection : 2:48 : clean output ports.
DEBUG	 FileReaderNodeModel           	 File Reader : 2:44 : Removing all (0) views from model.
DEBUG	 File Reader                   	 File Reader : 2:44 : clean output ports.
DEBUG	 HiveConnectorNodeModel        	 Hive Connector : 2:1 : Removing all (0) views from model.
DEBUG	 Hive Connector                	 Hive Connector : 2:1 : clean output ports.
DEBUG	 WorkflowManager               	 Project "Hive2Spark 2" removed (4 remaining)
2015-06-03 14:32:17,490 : DEBUG : ModalContext : HiveConnectorNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:17,606 : DEBUG : ModalContext : DBSQLExecutorNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:17,633 : DEBUG : ModalContext : DBTableSelectorNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:17,644 : DEBUG : ModalContext : FileReaderNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:17,721 : DEBUG : ModalContext : HiveLoaderNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:17,819 : DEBUG : ModalContext : SSHConnectionInformationNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:17,876 : DEBUG : ModalContext : Hive2SparkNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:17,936 : DEBUG : ModalContext : MLlibKMeansNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:17,950 : DEBUG : ModalContext : JavaSnippetNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:18,001 : DEBUG : ModalContext : SparkSnippetNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:18,015 : DEBUG : ModalContext : GroupByNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:18,026 : DEBUG : ModalContext : FileReaderNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:18,033 : DEBUG : ModalContext : LinReg2LearnerNodeFactory : Hive2Spark : 2 : Factory is already initialized. Nothing to do.
2015-06-03 14:32:18,087 : DEBUG : ModalContext : File Reader : File Reader : 2:55 : Configure succeeded. (File Reader)
2015-06-03 14:32:18,141 : DEBUG : ModalContext : Java Snippet : Java Snippet : 2:51 : Configure succeeded. (Java Snippet)
2015-06-03 14:32:18,157 : DEBUG : ModalContext : Linear Regression Learner : Linear Regression Learner : 2:56 : Configure succeeded. (Linear Regression Learner)
2015-06-03 14:32:19,073 : WARN  : ModalContext : Hive to Spark : Hive to Spark : 2:49 : Spark context no longer available. Reset node.
2015-06-03 14:32:19,114 : DEBUG : ModalContext : DataType : GroupBy : 2:54 : BitVectorValue is the preferred value class of cell implementation DenseBitVectorCell, made sanity check
2015-06-03 14:32:19,131 : WARN  : ModalContext : GroupBy : GroupBy : 2:54 : No grouping column included. Aggregate complete table.
2015-06-03 14:32:19,136 : DEBUG : ModalContext : GroupByNodeModel : GroupBy : 2:54 : [sepal width->Sum false]
2015-06-03 14:32:19,142 : DEBUG : ModalContext : GroupBy : GroupBy : 2:54 : Configure succeeded. (GroupBy)
2015-06-03 14:32:19,146 : DEBUG : ModalContext : Spark Snippet : Spark Snippet : 2:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:32:19,232 : WARN  : ModalContext : MLlib k-Means : MLlib k-Means : 2:50 : Spark context no longer available. Reset node.
2015-06-03 14:32:22,626 : DEBUG : main : Spark Snippet : Spark Snippet : 2:52 : reset
2015-06-03 14:32:22,768 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 2:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:32:22,772 : DEBUG : main : Spark Snippet : Spark Snippet : 2:52 : clean output ports.
2015-06-03 14:32:22,793 : DEBUG : main : MLlib k-Means : MLlib k-Means : 2:50 : reset
2015-06-03 14:32:22,797 : DEBUG : main : AbstractSparkNodeModel : MLlib k-Means : 2:50 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:32:22,801 : DEBUG : main : MLlib k-Means : MLlib k-Means : 2:50 : clean output ports.
2015-06-03 14:32:22,814 : DEBUG : main : Hive to Spark : Hive to Spark : 2:49 : reset
2015-06-03 14:32:22,817 : DEBUG : main : AbstractSparkNodeModel : Hive to Spark : 2:49 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:32:22,821 : DEBUG : main : Hive to Spark : Hive to Spark : 2:49 : clean output ports.
2015-06-03 14:32:23,041 : DEBUG : main : Hive to Spark : Hive to Spark : 2:49 : Configure succeeded. (Hive to Spark)
2015-06-03 14:32:23,051 : DEBUG : main : Spark Snippet : Spark Snippet : 2:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:32:23,059 : DEBUG : main : MLlib k-Means : MLlib k-Means : 2:50 : Configure succeeded. (MLlib k-Means)
2015-06-03 14:32:24,495 : DEBUG : KNIME-Worker-6 : WorkflowManager : Hive to Spark : 2:49 : Hive to Spark 2:49 doBeforePreExecution
2015-06-03 14:32:24,599 : DEBUG : KNIME-Worker-6 : NodeContainer : Hive to Spark : 2:49 : Hive to Spark 2:49 has new state: PREEXECUTE
2015-06-03 14:32:24,602 : DEBUG : KNIME-Worker-6 : WorkflowManager : Hive to Spark : 2:49 : Hive to Spark 2:49 doBeforeExecution
2015-06-03 14:32:24,605 : DEBUG : KNIME-Worker-6 : NodeContainer : Hive to Spark : 2:49 : Hive to Spark 2:49 has new state: EXECUTING
2015-06-03 14:32:24,608 : DEBUG : KNIME-Worker-6 : WorkflowFileStoreHandlerRepository : Hive to Spark : 2:49 : Adding handler c378599e-d2eb-43c3-9830-4468604170f0 (Hive to Spark 2:49: <no directory>) - 1 in total
2015-06-03 14:32:24,612 : DEBUG : KNIME-Worker-6 : LocalNodeExecutionJob : Hive to Spark : 2:49 : Hive to Spark 2:49 Start execute
2015-06-03 14:32:29,952 : INFO  : KNIME-Worker-6 : LocalNodeExecutionJob : Hive to Spark : 2:49 : Hive to Spark 2:49 End execute (5 secs)
2015-06-03 14:32:29,955 : DEBUG : KNIME-Worker-6 : WorkflowManager : Hive to Spark : 2:49 : Hive to Spark 2:49 doBeforePostExecution
2015-06-03 14:32:29,958 : DEBUG : KNIME-Worker-6 : NodeContainer : Hive to Spark : 2:49 : Hive to Spark 2:49 has new state: POSTEXECUTE
2015-06-03 14:32:29,962 : DEBUG : KNIME-Worker-6 : WorkflowManager : Hive to Spark : 2:49 : Hive to Spark 2:49 doAfterExecute - success
2015-06-03 14:32:29,967 : DEBUG : KNIME-Worker-6 : NodeContainer : Hive to Spark : 2:49 : Hive to Spark 2:49 has new state: EXECUTED
2015-06-03 14:32:29,970 : DEBUG : KNIME-Worker-6 : Spark Snippet : Spark Snippet : 2:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:32:29,973 : DEBUG : KNIME-Worker-6 : MLlib k-Means : MLlib k-Means : 2:50 : Configure succeeded. (MLlib k-Means)
2015-06-03 14:32:29,975 : DEBUG : KNIME-Worker-6 : NodeContainer : Hive to Spark : 2:49 : MLlib k-Means 2:50 has new state: CONFIGURED_QUEUED
2015-06-03 14:32:29,979 : DEBUG : KNIME-Worker-7 : WorkflowManager : MLlib k-Means : 2:50 : MLlib k-Means 2:50 doBeforePreExecution
2015-06-03 14:32:30,205 : DEBUG : KNIME-Worker-7 : NodeContainer : MLlib k-Means : 2:50 : MLlib k-Means 2:50 has new state: PREEXECUTE
2015-06-03 14:32:30,209 : DEBUG : KNIME-Worker-7 : WorkflowManager : MLlib k-Means : 2:50 : MLlib k-Means 2:50 doBeforeExecution
2015-06-03 14:32:30,213 : DEBUG : KNIME-Worker-7 : NodeContainer : MLlib k-Means : 2:50 : MLlib k-Means 2:50 has new state: EXECUTING
2015-06-03 14:32:30,217 : DEBUG : KNIME-Worker-7 : WorkflowFileStoreHandlerRepository : MLlib k-Means : 2:50 : Adding handler 186a1b5a-0f76-4733-a251-ea1f4614d3ec (MLlib k-Means 2:50: <no directory>) - 2 in total
2015-06-03 14:32:30,220 : DEBUG : KNIME-Worker-7 : LocalNodeExecutionJob : MLlib k-Means : 2:50 : MLlib k-Means 2:50 Start execute
2015-06-03 14:32:34,341 : INFO  : KNIME-Worker-7 : LocalNodeExecutionJob : MLlib k-Means : 2:50 : MLlib k-Means 2:50 End execute (4 secs)
2015-06-03 14:32:34,344 : DEBUG : KNIME-Worker-7 : WorkflowManager : MLlib k-Means : 2:50 : MLlib k-Means 2:50 doBeforePostExecution
2015-06-03 14:32:34,347 : DEBUG : KNIME-Worker-7 : NodeContainer : MLlib k-Means : 2:50 : MLlib k-Means 2:50 has new state: POSTEXECUTE
2015-06-03 14:32:34,350 : DEBUG : KNIME-Worker-7 : WorkflowManager : MLlib k-Means : 2:50 : MLlib k-Means 2:50 doAfterExecute - success
2015-06-03 14:32:34,352 : DEBUG : KNIME-Worker-7 : NodeContainer : MLlib k-Means : 2:50 : MLlib k-Means 2:50 has new state: EXECUTED
2015-06-03 14:32:34,355 : DEBUG : KNIME-Worker-7 : NodeContainer : MLlib k-Means : 2:50 : Hive2Spark 2 has new state: CONFIGURED
2015-06-03 14:33:01,160 : DEBUG : main : Spark Snippet : Spark Snippet : 2:52 : reset
2015-06-03 14:33:01,165 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 2:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:33:01,169 : DEBUG : main : Spark Snippet : Spark Snippet : 2:52 : clean output ports.
2015-06-03 14:33:01,185 : DEBUG : main : MLlib k-Means : MLlib k-Means : 2:50 : reset
2015-06-03 14:33:01,188 : DEBUG : main : AbstractSparkNodeModel : MLlib k-Means : 2:50 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:33:01,192 : DEBUG : main : MLlib k-Means : MLlib k-Means : 2:50 : clean output ports.
2015-06-03 14:33:01,208 : DEBUG : main : Hive to Spark : Hive to Spark : 2:49 : reset
2015-06-03 14:33:01,212 : DEBUG : main : AbstractSparkNodeModel : Hive to Spark : 2:49 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:33:01,215 : DEBUG : main : Hive to Spark : Hive to Spark : 2:49 : clean output ports.
2015-06-03 14:33:01,241 : DEBUG : main : Hive to Spark : Hive to Spark : 2:49 : Configure succeeded. (Hive to Spark)
2015-06-03 14:33:01,251 : DEBUG : main : Spark Snippet : Spark Snippet : 2:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:33:01,259 : DEBUG : main : MLlib k-Means : MLlib k-Means : 2:50 : Configure succeeded. (MLlib k-Means)
2015-06-03 14:33:03,946 : DEBUG : main : MLlibKMeansNodeModel : MLlib k-Means : 2:50 : Removing all (0) views from model.
2015-06-03 14:33:03,952 : DEBUG : main : MLlib k-Means : MLlib k-Means : 2:50 : clean output ports.
2015-06-03 14:33:03,955 : DEBUG : main : SparkSnippetNodeModel : Spark Snippet : 2:52 : Removing all (0) views from model.
2015-06-03 14:33:03,959 : DEBUG : main : Spark Snippet : Spark Snippet : 2:52 : clean output ports.
2015-06-03 14:33:03,963 : DEBUG : main : GroupByNodeModel : GroupBy : 2:54 : Removing all (0) views from model.
2015-06-03 14:33:03,966 : DEBUG : main : GroupBy : GroupBy : 2:54 : clean output ports.
2015-06-03 14:33:03,970 : DEBUG : main : Hive2SparkNodeModel : Hive to Spark : 2:49 : Removing all (0) views from model.
2015-06-03 14:33:03,975 : DEBUG : main : Hive to Spark : Hive to Spark : 2:49 : clean output ports.
2015-06-03 14:33:03,980 : DEBUG : main : DBTableSelectorNodeModel : Database Table Selector : 2:43 : Removing all (0) views from model.
2015-06-03 14:33:03,985 : DEBUG : main : Database Table Selector : Database Table Selector : 2:43 : clean output ports.
2015-06-03 14:33:03,989 : DEBUG : main : LinReg2LearnerNodeModel : Linear Regression Learner : 2:56 : Removing all (0) views from model.
2015-06-03 14:33:03,993 : DEBUG : main : Linear Regression Learner : Linear Regression Learner : 2:56 : clean output ports.
2015-06-03 14:33:03,997 : DEBUG : main : JavaSnippetNodeModel : Java Snippet : 2:51 : Removing all (0) views from model.
2015-06-03 14:33:04,000 : DEBUG : main : Java Snippet : Java Snippet : 2:51 : clean output ports.
2015-06-03 14:33:04,004 : DEBUG : main : HiveLoaderNodeModel : Hive Loader : 2:46 : Removing all (0) views from model.
2015-06-03 14:33:04,008 : DEBUG : main : Hive Loader : Hive Loader : 2:46 : clean output ports.
2015-06-03 14:33:04,014 : DEBUG : main : DBSQLExecutorNodeModel : Database SQL Executor : 2:42 : Removing all (0) views from model.
2015-06-03 14:33:04,018 : DEBUG : main : Database SQL Executor : Database SQL Executor : 2:42 : clean output ports.
2015-06-03 14:33:04,022 : DEBUG : main : FileReaderNodeModel : File Reader : 2:55 : Removing all (0) views from model.
2015-06-03 14:33:04,026 : DEBUG : main : File Reader : File Reader : 2:55 : clean output ports.
2015-06-03 14:33:04,030 : DEBUG : main : ConnectionInformationNodeModel : SSH Connection : 2:48 : Removing all (0) views from model.
2015-06-03 14:33:04,034 : DEBUG : main : SSH Connection : SSH Connection : 2:48 : clean output ports.
2015-06-03 14:33:04,037 : DEBUG : main : FileReaderNodeModel : File Reader : 2:44 : Removing all (0) views from model.
2015-06-03 14:33:04,042 : DEBUG : main : File Reader : File Reader : 2:44 : clean output ports.
2015-06-03 14:33:04,047 : DEBUG : main : HiveConnectorNodeModel : Hive Connector : 2:1 : Removing all (0) views from model.
2015-06-03 14:33:04,050 : DEBUG : main : Hive Connector : Hive Connector : 2:1 : clean output ports.
2015-06-03 14:35:30,051 : DEBUG : main : HiveConnectorNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,251 : DEBUG : main : DBSQLExecutorNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,291 : DEBUG : main : DBTableSelectorNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,320 : DEBUG : main : FileReaderNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,338 : DEBUG : main : HiveLoaderNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,364 : DEBUG : main : SSHConnectionInformationNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,379 : DEBUG : main : Hive2SparkNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,401 : DEBUG : main : MLlibKMeansNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,425 : DEBUG : main : JavaSnippetNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,462 : DEBUG : main : SparkSnippetNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,483 : DEBUG : main : GroupByNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,500 : DEBUG : main : FileReaderNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,516 : DEBUG : main : LinReg2LearnerNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 14:35:30,573 : DEBUG : main : DataType : File Reader : 0:44 : DoubleValue is the preferred value class of cell implementation DoubleCell, made sanity check
2015-06-03 14:35:30,587 : DEBUG : main : DataType : File Reader : 0:44 : StringValue is the preferred value class of cell implementation StringCell, made sanity check
2015-06-03 14:35:30,623 : DEBUG : main : File Reader : File Reader : 0:55 : Configure succeeded. (File Reader)
2015-06-03 14:35:31,097 : DEBUG : main : Java Snippet : Java Snippet : 0:51 : Configure succeeded. (Java Snippet)
2015-06-03 14:35:31,116 : DEBUG : main : Linear Regression Learner : Linear Regression Learner : 0:56 : Configure succeeded. (Linear Regression Learner)
2015-06-03 14:35:31,126 : DEBUG : main : DataType : Database Table Selector : 0:43 : IntValue is the preferred value class of cell implementation IntCell, made sanity check
2015-06-03 14:35:31,826 : DEBUG : main : Hive to Spark : Hive to Spark : 0:49 : Configure succeeded. (Hive to Spark)
2015-06-03 14:35:31,862 : DEBUG : main : DataType : GroupBy : 0:54 : DateAndTimeValue is the preferred value class of cell implementation DateAndTimeCell, made sanity check
2015-06-03 14:35:31,869 : DEBUG : main : DataType : GroupBy : 0:54 : LongValue is the preferred value class of cell implementation LongCell, made sanity check
2015-06-03 14:35:31,876 : DEBUG : main : DataType : GroupBy : 0:54 : BitVectorValue is the preferred value class of cell implementation DenseBitVectorCell, made sanity check
2015-06-03 14:35:31,891 : WARN  : main : GroupBy : GroupBy : 0:54 : No grouping column included. Aggregate complete table.
2015-06-03 14:35:31,897 : DEBUG : main : GroupByNodeModel : GroupBy : 0:54 : [sepal width->Sum false]
2015-06-03 14:35:31,903 : DEBUG : main : GroupBy : GroupBy : 0:54 : Configure succeeded. (GroupBy)
2015-06-03 14:35:31,907 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:35:31,913 : DEBUG : main : MLlib k-Means : MLlib k-Means : 0:50 : Configure succeeded. (MLlib k-Means)
2015-06-03 14:35:38,443 : DEBUG : KNIME-Worker-0 : WorkflowManager : Hive to Spark : 0:49 : Hive to Spark 0:49 doBeforePreExecution
2015-06-03 14:35:38,559 : DEBUG : KNIME-Worker-0 : NodeContainer : Hive to Spark : 0:49 : Hive to Spark 0:49 has new state: PREEXECUTE
2015-06-03 14:35:38,562 : DEBUG : KNIME-Worker-0 : WorkflowManager : Hive to Spark : 0:49 : Hive to Spark 0:49 doBeforeExecution
2015-06-03 14:35:38,565 : DEBUG : KNIME-Worker-0 : NodeContainer : Hive to Spark : 0:49 : Hive to Spark 0:49 has new state: EXECUTING
2015-06-03 14:35:38,571 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Hive to Spark : 0:49 : Adding handler 64dd0658-ed85-4344-aae0-1438038b5c0d (Hive to Spark 0:49: <no directory>) - 1 in total
2015-06-03 14:35:38,575 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Hive to Spark : 0:49 : Hive to Spark 0:49 Start execute
2015-06-03 14:35:40,188 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : Hive to Spark : 0:49 : Hive to Spark 0:49 End execute (1 sec)
2015-06-03 14:35:40,190 : DEBUG : KNIME-Worker-0 : WorkflowManager : Hive to Spark : 0:49 : Hive to Spark 0:49 doBeforePostExecution
2015-06-03 14:35:40,191 : DEBUG : KNIME-Worker-0 : NodeContainer : Hive to Spark : 0:49 : Hive to Spark 0:49 has new state: POSTEXECUTE
2015-06-03 14:35:40,296 : DEBUG : KNIME-Worker-0 : WorkflowManager : Hive to Spark : 0:49 : Hive to Spark 0:49 doAfterExecute - success
2015-06-03 14:35:40,298 : DEBUG : KNIME-Worker-0 : NodeContainer : Hive to Spark : 0:49 : Hive to Spark 0:49 has new state: EXECUTED
2015-06-03 14:35:40,302 : DEBUG : KNIME-Worker-0 : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:35:40,305 : DEBUG : KNIME-Worker-0 : MLlib k-Means : MLlib k-Means : 0:50 : Configure succeeded. (MLlib k-Means)
2015-06-03 14:35:40,308 : DEBUG : KNIME-Worker-0 : NodeContainer : Hive to Spark : 0:49 : MLlib k-Means 0:50 has new state: CONFIGURED_QUEUED
2015-06-03 14:35:40,311 : DEBUG : KNIME-Worker-1 : WorkflowManager : MLlib k-Means : 0:50 : MLlib k-Means 0:50 doBeforePreExecution
2015-06-03 14:35:40,511 : DEBUG : KNIME-Worker-1 : NodeContainer : MLlib k-Means : 0:50 : MLlib k-Means 0:50 has new state: PREEXECUTE
2015-06-03 14:35:40,514 : DEBUG : KNIME-Worker-1 : WorkflowManager : MLlib k-Means : 0:50 : MLlib k-Means 0:50 doBeforeExecution
2015-06-03 14:35:40,517 : DEBUG : KNIME-Worker-1 : NodeContainer : MLlib k-Means : 0:50 : MLlib k-Means 0:50 has new state: EXECUTING
2015-06-03 14:35:40,522 : DEBUG : KNIME-Worker-1 : WorkflowFileStoreHandlerRepository : MLlib k-Means : 0:50 : Adding handler ab4770df-9758-4140-b6cb-a1e38ed1567f (MLlib k-Means 0:50: <no directory>) - 2 in total
2015-06-03 14:35:40,525 : DEBUG : KNIME-Worker-1 : LocalNodeExecutionJob : MLlib k-Means : 0:50 : MLlib k-Means 0:50 Start execute
2015-06-03 14:35:42,659 : INFO  : KNIME-Worker-1 : LocalNodeExecutionJob : MLlib k-Means : 0:50 : MLlib k-Means 0:50 End execute (2 secs)
2015-06-03 14:35:42,661 : DEBUG : KNIME-Worker-1 : WorkflowManager : MLlib k-Means : 0:50 : MLlib k-Means 0:50 doBeforePostExecution
2015-06-03 14:35:42,664 : DEBUG : KNIME-Worker-1 : NodeContainer : MLlib k-Means : 0:50 : MLlib k-Means 0:50 has new state: POSTEXECUTE
2015-06-03 14:35:42,666 : DEBUG : KNIME-Worker-1 : WorkflowManager : MLlib k-Means : 0:50 : MLlib k-Means 0:50 doAfterExecute - success
2015-06-03 14:35:42,668 : DEBUG : KNIME-Worker-1 : NodeContainer : MLlib k-Means : 0:50 : MLlib k-Means 0:50 has new state: EXECUTED
2015-06-03 14:35:42,670 : DEBUG : KNIME-Worker-1 : NodeContainer : MLlib k-Means : 0:50 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 14:35:43,905 : DEBUG : AWT-EventQueue-0 : DataType : MLlib k-Means : 0:50 : Class "DataCell" doesn't have a default value class (it does not implement a static method "getPreferredValueClass()"). Returning null
2015-06-03 14:35:44,030 : DEBUG : KNIME-TableIO-1 : DataType : MLlib k-Means : 0:50 : MissingValue is the preferred value class of cell implementation MissingCell, made sanity check
2015-06-03 14:35:59,786 : DEBUG : KNIME-Worker-0 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforePreExecution
2015-06-03 14:35:59,789 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: PREEXECUTE
2015-06-03 14:35:59,791 : DEBUG : KNIME-Worker-0 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforeExecution
2015-06-03 14:35:59,793 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: EXECUTING
2015-06-03 14:35:59,795 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:52 : Adding handler 585f187c-48bf-4c3c-bce8-849029af7a8b (Spark Snippet 0:52: <no directory>) - 3 in total
2015-06-03 14:35:59,797 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Spark Snippet : 0:52 : Spark Snippet 0:52 Start execute
2015-06-03 14:36:05,988 : DEBUG : KNIME-Worker-0 : JavaCodeCompiler : Spark Snippet : 0:52 : Error output of compilation:
----------
1. ERROR in \kt0_a3d9d45f363f5a1c.java (at line 159)
	return aInput1.join(aInput2);
	               ^^^^
The method join(T) is undefined for the type T
----------
1 problem (1 error)
2015-06-03 14:36:05,992 : DEBUG : KNIME-Worker-0 : JavaCodeCompiler : Spark Snippet : 0:52 : Command line arguments were: [-classpath, C:\DEVELOPMENT\workspaces\trunk\.metadata\.plugins\org.eclipse.pde.core\.bundle_pool\plugins\org.eclipse.equinox.launcher_1.2.0.v20110502.jar;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\lib\job-server-api_2.10-0.5.1-SNAPSHOT.jar;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\bin;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\lib\knimeSparkScalaClient.jar;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\lib\spark-assembly-1.2.1-hadoop2.4.0.jar, -source, 1.7, -target, 1.7, -nowarn]
2015-06-03 14:36:05,998 : DEBUG : KNIME-Worker-0 : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:36:06,001 : DEBUG : KNIME-Worker-0 : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:36:06,005 : ERROR : KNIME-Worker-0 : Spark Snippet : Spark Snippet : 0:52 : Execute failed: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
The method join(T) is undefined for the type T
2015-06-03 14:36:06,009 : DEBUG : KNIME-Worker-0 : Spark Snippet : Spark Snippet : 0:52 : Execute failed: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
The method join(T) is undefined for the type T
com.knime.bigdata.spark.jobserver.server.GenericKnimeSparkException: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
The method join(T) is undefined for the type T
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler.compileAndCreateInstance(SparkJobCompiler.java:153)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler.addTransformationSparkJob2Jar(SparkJobCompiler.java:115)
	at com.knime.bigdata.spark.node.scripting.snippet.SparkSnippetNodeModel.addTransformationJob2Jar(SparkSnippetNodeModel.java:197)
	at com.knime.bigdata.spark.node.scripting.snippet.SparkSnippetNodeModel.executeInternal(SparkSnippetNodeModel.java:101)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.execute(AbstractSparkNodeModel.java:113)
	at org.knime.core.node.NodeModel.executeModel(NodeModel.java:559)
	at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1134)
	at org.knime.core.node.Node.execute(Node.java:930)
	at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:559)
	at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)
	at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)
	at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)
	at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)
	at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:125)
	at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:248)
Caused by: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
The method join(T) is undefined for the type T
	at org.knime.ext.sun.nodes.script.compile.JavaCodeCompiler.compile(JavaCodeCompiler.java:281)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler$SourceCompiler.compileCode(SparkJobCompiler.java:343)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler$SourceCompiler.setCode(SparkJobCompiler.java:320)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler$SourceCompiler.<init>(SparkJobCompiler.java:296)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler.compileAndCreateInstance(SparkJobCompiler.java:150)
	... 17 more
2015-06-03 14:36:13,464 : DEBUG : KNIME-Worker-0 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforePostExecution
2015-06-03 14:36:13,465 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: POSTEXECUTE
2015-06-03 14:36:13,466 : DEBUG : KNIME-Worker-0 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doAfterExecute - failure
2015-06-03 14:36:13,466 : DEBUG : KNIME-Worker-0 : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:36:13,466 : DEBUG : KNIME-Worker-0 : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:36:13,466 : DEBUG : KNIME-Worker-0 : Spark Snippet : Spark Snippet : 0:52 : clean output ports.
2015-06-03 14:36:13,467 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:52 : Removing handler 585f187c-48bf-4c3c-bce8-849029af7a8b (Spark Snippet 0:52: <no directory>) - 2 remaining
2015-06-03 14:36:13,467 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: IDLE
2015-06-03 14:36:13,468 : DEBUG : KNIME-Worker-0 : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:36:13,468 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: CONFIGURED
2015-06-03 14:36:13,468 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 14:36:28,677 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:36:28,678 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:36:28,678 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : clean output ports.
2015-06-03 14:36:28,679 : DEBUG : main : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: IDLE
2015-06-03 14:36:28,679 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:36:28,680 : DEBUG : main : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: CONFIGURED
2015-06-03 14:36:29,728 : DEBUG : KNIME-WFM-Parent-Notifier : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforePreExecution
2015-06-03 14:36:29,729 : DEBUG : KNIME-Worker-1 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: PREEXECUTE
2015-06-03 14:36:29,729 : DEBUG : KNIME-Worker-1 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforeExecution
2015-06-03 14:36:29,729 : DEBUG : KNIME-Worker-1 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: EXECUTING
2015-06-03 14:36:29,730 : DEBUG : KNIME-Worker-1 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:52 : Adding handler 37e3cf67-ab3b-46db-b838-e7c059c57bbe (Spark Snippet 0:52: <no directory>) - 3 in total
2015-06-03 14:36:29,730 : DEBUG : KNIME-Worker-1 : LocalNodeExecutionJob : Spark Snippet : 0:52 : Spark Snippet 0:52 Start execute
2015-06-03 14:36:31,042 : DEBUG : KNIME-Worker-1 : DataType : Spark Snippet : 0:52 : BooleanValue is the preferred value class of cell implementation BooleanCell, made sanity check
2015-06-03 14:36:31,043 : INFO  : KNIME-Worker-1 : LocalNodeExecutionJob : Spark Snippet : 0:52 : Spark Snippet 0:52 End execute (1 sec)
2015-06-03 14:36:31,043 : DEBUG : KNIME-Worker-1 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforePostExecution
2015-06-03 14:36:31,043 : DEBUG : KNIME-Worker-1 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: POSTEXECUTE
2015-06-03 14:36:31,043 : DEBUG : KNIME-Worker-1 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doAfterExecute - success
2015-06-03 14:36:31,043 : DEBUG : KNIME-Worker-1 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: EXECUTED
2015-06-03 14:36:31,044 : DEBUG : KNIME-Worker-1 : NodeContainer : Spark Snippet : 0:52 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 14:37:37,286 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:37:37,287 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:37:37,287 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : clean output ports.
2015-06-03 14:37:37,289 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:37:37,289 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:37:37,290 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:37:37,290 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : clean output ports.
2015-06-03 14:37:37,290 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:37:41,904 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:37:41,904 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:37:41,905 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : clean output ports.
2015-06-03 14:37:41,905 : DEBUG : main : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: IDLE
2015-06-03 14:37:41,906 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:37:41,906 : DEBUG : main : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: CONFIGURED
2015-06-03 14:37:41,954 : DEBUG : main : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: CONFIGURED_MARKEDFOREXEC
2015-06-03 14:37:41,955 : DEBUG : main : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: CONFIGURED_QUEUED
2015-06-03 14:37:41,955 : DEBUG : main : NodeContainer : Spark Snippet : 0:52 : Hive2Spark 0 has new state: EXECUTING
2015-06-03 14:37:41,955 : DEBUG : 2015-06-03 14:37:41,955 : KNIME-WFM-Parent-Notifier : DEBUG : NodeContainer : KNIME-Worker-0 : WorkflowManager : ROOT  has new state: EXECUTING
Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforePreExecution
2015-06-03 14:37:41,956 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: PREEXECUTE
2015-06-03 14:37:41,956 : DEBUG : KNIME-Worker-0 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforeExecution
2015-06-03 14:37:41,956 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: EXECUTING
2015-06-03 14:37:41,957 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:52 : Adding handler 89e2f07f-450e-4b95-a059-f95e026a71a7 (Spark Snippet 0:52: <no directory>) - 3 in total
2015-06-03 14:37:41,957 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Spark Snippet : 0:52 : Spark Snippet 0:52 Start execute
2015-06-03 14:37:43,154 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : Spark Snippet : 0:52 : Spark Snippet 0:52 End execute (1 sec)
2015-06-03 14:37:43,155 : DEBUG : KNIME-Worker-0 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforePostExecution
2015-06-03 14:37:43,155 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: POSTEXECUTE
2015-06-03 14:37:43,155 : DEBUG : KNIME-Worker-0 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doAfterExecute - success
2015-06-03 14:37:43,155 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: EXECUTED
2015-06-03 14:37:43,156 : DEBUG : KNIME-Worker-0 : NodeContainer : Spark Snippet : 0:52 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 14:45:38,697 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:45:38,697 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:45:38,698 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : clean output ports.
2015-06-03 14:45:38,699 : DEBUG : main : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:52 : Removing handler 89e2f07f-450e-4b95-a059-f95e026a71a7 (Spark Snippet 0:52: <no directory>) - 2 remaining
2015-06-03 14:45:38,700 : DEBUG : main : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: IDLE
2015-06-03 14:45:38,701 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:45:38,702 : DEBUG : main : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: CONFIGURED
2015-06-03 14:45:42,893 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:45:42,893 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:45:42,893 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : clean output ports.
2015-06-03 14:45:42,894 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforePreExecution
2015-06-03 14:45:44,259 : DEBUG : KNIME-Worker-2 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: PREEXECUTE
2015-06-03 14:45:44,259 : DEBUG : KNIME-Worker-2 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforeExecution
2015-06-03 14:45:44,260 : DEBUG : KNIME-Worker-2 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: EXECUTING
2015-06-03 14:45:44,260 : DEBUG : KNIME-Worker-2 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:52 : Adding handler 7a494352-2fdc-480c-93c4-b84741401c22 (Spark Snippet 0:52: <no directory>) - 3 in total
2015-06-03 14:45:44,260 : DEBUG : KNIME-Worker-2 : LocalNodeExecutionJob : Spark Snippet : 0:52 : Spark Snippet 0:52 Start execute
2015-06-03 14:45:44,453 : DEBUG : KNIME-Worker-2 : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:45:44,453 : DEBUG : KNIME-Worker-2 : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:45:44,453 : ERROR : KNIME-Worker-2 : Spark Snippet : Spark Snippet : 0:52 : Execute failed: Error: failed to start job: kt0_63414d6e594e0372
Possible reasons:
	'Bad Request' implies missing or incorrect parameters.	'Not Found' implies that class file with job info was not uploaded to server.
Status is: Not Found
Indication: InboundJaxrsResponse{ClientResponse{method=POST, uri=http://sandbox.hortonworks.com:8090/jobs/?appName=app&context=knime.spark.6c6e004f-4697-4162-8502-2416e857ce9d&classPath=kt0_63414d6e594e0372, status=404, reason=Not Found}}
2015-06-03 14:45:44,453 : DEBUG : KNIME-Worker-2 : Spark Snippet : Spark Snippet : 0:52 : Execute failed: Error: failed to start job: kt0_63414d6e594e0372
Possible reasons:
	'Bad Request' implies missing or incorrect parameters.	'Not Found' implies that class file with job info was not uploaded to server.
Status is: Not Found
Indication: InboundJaxrsResponse{ClientResponse{method=POST, uri=http://sandbox.hortonworks.com:8090/jobs/?appName=app&context=knime.spark.6c6e004f-4697-4162-8502-2416e857ce9d&classPath=kt0_63414d6e594e0372, status=404, reason=Not Found}}
com.knime.bigdata.spark.jobserver.server.GenericKnimeSparkException: Error: failed to start job: kt0_63414d6e594e0372
Possible reasons:
	'Bad Request' implies missing or incorrect parameters.	'Not Found' implies that class file with job info was not uploaded to server.
Status is: Not Found
Indication: InboundJaxrsResponse{ClientResponse{method=POST, uri=http://sandbox.hortonworks.com:8090/jobs/?appName=app&context=knime.spark.6c6e004f-4697-4162-8502-2416e857ce9d&classPath=kt0_63414d6e594e0372, status=404, reason=Not Found}}
	at com.knime.bigdata.spark.jobserver.client.WsRsRestClient.checkStatus(WsRsRestClient.java:76)
	at com.knime.bigdata.spark.jobserver.client.RestClient.checkStatus(RestClient.java:47)
	at com.knime.bigdata.spark.jobserver.client.JobControler.startJob(JobControler.java:138)
	at com.knime.bigdata.spark.node.scripting.snippet.SparkSnippetNodeModel.executeInternal(SparkSnippetNodeModel.java:107)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.execute(AbstractSparkNodeModel.java:113)
	at org.knime.core.node.NodeModel.executeModel(NodeModel.java:559)
	at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1134)
	at org.knime.core.node.Node.execute(Node.java:930)
	at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:559)
	at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)
	at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)
	at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)
	at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)
	at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:125)
	at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:248)
2015-06-03 14:45:44,454 : DEBUG : KNIME-Worker-2 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforePostExecution
2015-06-03 14:45:44,454 : DEBUG : KNIME-Worker-2 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: POSTEXECUTE
2015-06-03 14:45:44,454 : DEBUG : KNIME-Worker-2 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doAfterExecute - failure
2015-06-03 14:45:44,454 : DEBUG : KNIME-Worker-2 : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:45:44,455 : DEBUG : KNIME-Worker-2 : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:45:44,455 : DEBUG : KNIME-Worker-2 : Spark Snippet : Spark Snippet : 0:52 : clean output ports.
2015-06-03 14:45:44,455 : DEBUG : KNIME-Worker-2 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:52 : Removing handler 7a494352-2fdc-480c-93c4-b84741401c22 (Spark Snippet 0:52: <no directory>) - 2 remaining
2015-06-03 14:45:44,455 : DEBUG : KNIME-Worker-2 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: IDLE
2015-06-03 14:45:44,455 : DEBUG : KNIME-Worker-2 : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:45:44,455 : DEBUG : KNIME-Worker-2 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: CONFIGURED
2015-06-03 14:45:44,456 : DEBUG : KNIME-Worker-2 : NodeContainer : Spark Snippet : 0:52 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 14:47:13,468 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : reset
2015-06-03 14:47:13,468 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:52 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:47:13,468 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : clean output ports.
2015-06-03 14:47:13,469 : DEBUG : main : MLlib k-Means : MLlib k-Means : 0:50 : reset
2015-06-03 14:47:13,469 : DEBUG : main : AbstractSparkNodeModel : MLlib k-Means : 0:50 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:47:13,469 : DEBUG : main : MLlib k-Means : MLlib k-Means : 0:50 : clean output ports.
2015-06-03 14:47:13,470 : DEBUG : main : Hive to Spark : Hive to Spark : 0:49 : reset
2015-06-03 14:47:13,470 : DEBUG : main : AbstractSparkNodeModel : Hive to Spark : 0:49 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:47:13,470 : DEBUG : main : Hive to Spark : Hive to Spark : 0:49 : clean output ports.
2015-06-03 14:47:13,624 : DEBUG : main : Hive to Spark : Hive to Spark : 0:49 : Configure succeeded. (Hive to Spark)
2015-06-03 14:47:13,625 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:47:13,625 : DEBUG : main : MLlib k-Means : MLlib k-Means : 0:50 : Configure succeeded. (MLlib k-Means)
2015-06-03 14:47:14,805 : DEBUG : 2015-06-03 14:47:14,805 : KNIME-Worker-3 : DEBUG : KNIME-WFM-Parent-NotifierWorkflowManager :  : NodeContainer : ROOT  has new state: EXECUTING
Hive to Spark : 0:49 : Hive to Spark 0:49 doBeforePreExecution
2015-06-03 14:47:14,806 : DEBUG : KNIME-Worker-3 : NodeContainer : Hive to Spark : 0:49 : Hive to Spark 0:49 has new state: PREEXECUTE
2015-06-03 14:47:14,806 : DEBUG : KNIME-Worker-3 : WorkflowManager : Hive to Spark : 0:49 : Hive to Spark 0:49 doBeforeExecution
2015-06-03 14:47:14,806 : DEBUG : KNIME-Worker-3 : NodeContainer : Hive to Spark : 0:49 : Hive to Spark 0:49 has new state: EXECUTING
2015-06-03 14:47:14,806 : DEBUG : KNIME-Worker-3 : WorkflowFileStoreHandlerRepository : Hive to Spark : 0:49 : Adding handler 804b4e56-7e93-4090-b387-826a4e64c39b (Hive to Spark 0:49: <no directory>) - 1 in total
2015-06-03 14:47:14,806 : DEBUG : KNIME-Worker-3 : LocalNodeExecutionJob : Hive to Spark : 0:49 : Hive to Spark 0:49 Start execute
2015-06-03 14:47:15,866 : INFO  : KNIME-Worker-3 : LocalNodeExecutionJob : Hive to Spark : 0:49 : Hive to Spark 0:49 End execute (1 sec)
2015-06-03 14:47:15,866 : DEBUG : KNIME-Worker-3 : WorkflowManager : Hive to Spark : 0:49 : Hive to Spark 0:49 doBeforePostExecution
2015-06-03 14:47:15,867 : DEBUG : KNIME-Worker-3 : NodeContainer : Hive to Spark : 0:49 : Hive to Spark 0:49 has new state: POSTEXECUTE
2015-06-03 14:47:15,867 : DEBUG : KNIME-Worker-3 : WorkflowManager : Hive to Spark : 0:49 : Hive to Spark 0:49 doAfterExecute - success
2015-06-03 14:47:15,867 : DEBUG : KNIME-Worker-3 : NodeContainer : Hive to Spark : 0:49 : Hive to Spark 0:49 has new state: EXECUTED
2015-06-03 14:47:15,867 : DEBUG : KNIME-Worker-3 : Spark Snippet : Spark Snippet : 0:52 : Configure succeeded. (Spark Snippet)
2015-06-03 14:47:15,868 : DEBUG : KNIME-Worker-3 : MLlib k-Means : MLlib k-Means : 0:50 : Configure succeeded. (MLlib k-Means)
2015-06-03 14:47:15,868 : DEBUG : KNIME-Worker-3 : NodeContainer : Hive to Spark : 0:49 : Hive2Spark 0 has new state: CONFIGURED
KNIME-Worker-4 : WorkflowManager : 2015-06-03 14:47:24,189 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforePreExecution
2015-06-03 14:47:24,189 : DEBUG : KNIME-Worker-4 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: PREEXECUTE
2015-06-03 14:47:24,190 : DEBUG : KNIME-Worker-4 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforeExecution
2015-06-03 14:47:24,190 : DEBUG : KNIME-Worker-4 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: EXECUTING
2015-06-03 14:47:24,190 : DEBUG : KNIME-Worker-4 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:52 : Adding handler 069f0513-f4c2-44af-8093-c2753d6ca252 (Spark Snippet 0:52: <no directory>) - 2 in total
2015-06-03 14:47:24,190 : DEBUG : KNIME-Worker-4 : LocalNodeExecutionJob : Spark Snippet : 0:52 : Spark Snippet 0:52 Start execute
2015-06-03 14:47:25,401 : INFO  : KNIME-Worker-4 : LocalNodeExecutionJob : Spark Snippet : 0:52 : Spark Snippet 0:52 End execute (1 sec)
2015-06-03 14:47:25,401 : DEBUG : KNIME-Worker-4 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doBeforePostExecution
2015-06-03 14:47:25,401 : DEBUG : KNIME-Worker-4 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: POSTEXECUTE
2015-06-03 14:47:25,401 : DEBUG : KNIME-Worker-4 : WorkflowManager : Spark Snippet : 0:52 : Spark Snippet 0:52 doAfterExecute - success
2015-06-03 14:47:25,402 : DEBUG : KNIME-Worker-4 : NodeContainer : Spark Snippet : 0:52 : Spark Snippet 0:52 has new state: EXECUTED
2015-06-03 14:47:25,402 : DEBUG : KNIME-Worker-4 : NodeContainer : Spark Snippet : 0:52 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 14:48:30,933 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : reset
WorkflowRoot: workflow changed, refreshing children/connections..
2015-06-03 14:48:30,933 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:57 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:48:30,933 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : clean output ports.
2015-06-03 14:48:32,869 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : Configure succeeded. (Spark Snippet)
2015-06-03 14:48:34,525 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 14:48:34,525 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:48:34,526 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : clean output ports.
2015-06-03 14:51:43,383 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : reset
2015-06-03 14:51:43,383 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:57 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:51:43,383 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : clean output ports.
2015-06-03 14:51:43,384 : DEBUG : main : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: IDLE
2015-06-03 14:51:43,384 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : Configure succeeded. (Spark Snippet)
2015-06-03 14:51:43,384 : DEBUG : main : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: CONFIGURED
2015-06-03 14:51:43,397 : DEBUG : main : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: CONFIGURED_MARKEDFOREXEC
2015-06-03 14:51:43,397 : DEBUG : main : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: CONFIGURED_QUEUED
2015-06-03 14:51:43,398 : DEBUG : main : NodeContainer : Spark Snippet : 0:57 : Hive2Spark 0 has new state: EXECUTING
2015-06-03 14:51:43,398 : DEBUG : KNIME-Worker-5 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doBeforePreExecution
2015-06-03 14:51:43,398 : DEBUG : KNIME-Worker-5 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: PREEXECUTE
2015-06-03 14:51:43,399 : DEBUG : KNIME-Worker-5 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doBeforeExecution
2015-06-03 14:51:43,399 : DEBUG : KNIME-Worker-5 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: EXECUTING
2015-06-03 14:51:43,399 : DEBUG : KNIME-Worker-5 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:57 : Adding handler 647f8a50-9387-45fa-9783-69e7fc3c3199 (Spark Snippet 0:57: <no directory>) - 3 in total
2015-06-03 14:51:43,399 : DEBUG : KNIME-Worker-5 : LocalNodeExecutionJob : Spark Snippet : 0:57 : Spark Snippet 0:57 Start execute
2015-06-03 14:51:44,590 : INFO  : KNIME-Worker-5 : LocalNodeExecutionJob : Spark Snippet : 0:57 : Spark Snippet 0:57 End execute (1 sec)
2015-06-03 14:51:44,591 : DEBUG : KNIME-Worker-5 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doBeforePostExecution
2015-06-03 14:51:44,591 : DEBUG : KNIME-Worker-5 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: POSTEXECUTE
2015-06-03 14:51:44,591 : DEBUG : KNIME-Worker-5 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doAfterExecute - success
2015-06-03 14:51:44,591 : DEBUG : KNIME-Worker-5 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: EXECUTED
2015-06-03 14:51:44,591 : DEBUG : KNIME-Worker-5 : Spark Snippet : Spark Snippet : 0:58 : Configure succeeded. (Spark Snippet)
2015-06-03 14:51:44,592 : DEBUG : KNIME-Worker-5 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:58 has new state: CONFIGURED
2015-06-03 14:51:44,592 : DEBUG : KNIME-Worker-5 : NodeContainer : Spark Snippet : 0:57 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 14:54:55,979 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 14:54:55,979 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:54:55,979 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : clean output ports.
2015-06-03 14:54:55,980 : DEBUG : main : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:58 has new state: IDLE
2015-06-03 14:54:55,980 : DEBUG : main : NodeContainer : Spark Snippet : 0:57 : Hive2Spark 0 has new state: IDLE
2015-06-03 14:54:55,980 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : reset
2015-06-03 14:54:55,981 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:57 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 14:54:55,981 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : clean output ports.
2015-06-03 14:54:55,981 : DEBUG : main : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:57 : Removing handler 647f8a50-9387-45fa-9783-69e7fc3c3199 (Spark Snippet 0:57: <no directory>) - 2 remaining
2015-06-03 14:54:55,981 : DEBUG : main : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: IDLE
2015-06-03 14:54:55,982 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : Configure succeeded. (Spark Snippet)
2015-06-03 14:54:55,982 : DEBUG : main : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: CONFIGURED
2015-06-03 14:54:57,203 : DEBUG : Spark Snippet : 0:57 : Spark Snippet 0:57 doBeforePreExecution
2015-06-03 14:54:57,204 : DEBUG : KNIME-Worker-6 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: PREEXECUTE
2015-06-03 14:54:57,204 : DEBUG : KNIME-Worker-6 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doBeforeExecution
2015-06-03 14:54:57,204 : DEBUG : KNIME-Worker-6 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: EXECUTING
2015-06-03 14:54:57,204 : DEBUG : KNIME-Worker-6 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:57 : Adding handler b75ce6e5-b6c4-464c-8863-997043ce095a (Spark Snippet 0:57: <no directory>) - 3 in total
2015-06-03 14:54:57,204 : DEBUG : KNIME-Worker-6 : LocalNodeExecutionJob : Spark Snippet : 0:57 : Spark Snippet 0:57 Start execute
2015-06-03 14:54:58,403 : INFO  : KNIME-Worker-6 : LocalNodeExecutionJob : Spark Snippet : 0:57 : Spark Snippet 0:57 End execute (1 sec)
2015-06-03 14:54:58,403 : DEBUG : KNIME-Worker-6 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doBeforePostExecution
2015-06-03 14:54:58,403 : DEBUG : KNIME-Worker-6 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: POSTEXECUTE
2015-06-03 14:54:58,403 : DEBUG : KNIME-Worker-6 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doAfterExecute - success
2015-06-03 14:54:58,403 : DEBUG : KNIME-Worker-6 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: EXECUTED
2015-06-03 14:54:58,404 : DEBUG : KNIME-Worker-6 : Spark Snippet : Spark Snippet : 0:58 : Configure succeeded. (Spark Snippet)
2015-06-03 14:54:58,404 : DEBUG : KNIME-Worker-6 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:58 has new state: CONFIGURED
2015-06-03 14:54:58,404 : DEBUG : KNIME-Worker-6 : NodeContainer : Spark Snippet : 0:57 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 15:13:09,700 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 15:13:09,701 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 15:13:09,701 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : clean output ports.
2015-06-03 15:13:09,701 : DEBUG : main : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: IDLE
2015-06-03 15:13:09,702 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : Configure succeeded. (Spark Snippet)
2015-06-03 15:13:09,702 : DEBUG : main : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: CONFIGURED
2015-06-03 15:13:23,942 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 15:13:23,942 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 15:13:23,942 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : clean output ports.
2015-06-03 15:13:23,943 : DEBUG : main : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: IDLE
2015-06-03 15:13:23,943 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : Configure succeeded. (Spark Snippet)
2015-06-03 15:13:23,944 : DEBUG : main : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: CONFIGURED
2015-06-03 15:13:37,388 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 15:13:37,389 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 15:13:37,389 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : clean output ports.
2015-06-03 15:13:37,389 : DEBUG : main : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: IDLE
2015-06-03 15:13:37,390 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : Configure succeeded. (Spark Snippet)
2015-06-03 15:13:37,390 : DEBUG : main : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: CONFIGURED
2015-06-03 15:13:38,504 : DEBUG : KNIME-Worker-7 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforePreExecution
2015-06-03 15:13:38,504 : DEBUG : KNIME-Worker-7 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: PREEXECUTE
2015-06-03 15:13:38,504 : DEBUG : KNIME-Worker-7 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforeExecution
2015-06-03 15:13:38,504 : DEBUG : KNIME-Worker-7 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: EXECUTING
2015-06-03 15:13:38,504 : DEBUG : KNIME-Worker-7 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:58 : Adding handler 18db94d9-7be0-4153-aab5-3c056a56a5f0 (Spark Snippet 0:58: <no directory>) - 4 in total
2015-06-03 15:13:38,505 : DEBUG : KNIME-Worker-7 : LocalNodeExecutionJob : Spark Snippet : 0:58 : Spark Snippet 0:58 Start execute
2015-06-03 15:13:38,672 : DEBUG : KNIME-Worker-7 : JavaCodeCompiler : Spark Snippet : 0:58 : Error output of compilation:
----------
1. ERROR in \kt0_696d720ab496f3fd.java (at line 159)
	JavaPairRDD<String, Row> pair1 = aInput1.mapToPair(new PairFunction<Row, String, Row>() {
	                                         ^^^^^^^^^
The method mapToPair(PairFunction<Row,K2,V2>) in the type JavaRDD<Row> is not applicable for the arguments (new PairFunction<Row,String,Row>(){})
----------
2. ERROR in \kt0_696d720ab496f3fd.java (at line 159)
	JavaPairRDD<String, Row> pair1 = aInput1.mapToPair(new PairFunction<Row, String, Row>() {
	                                                       ^^^^^^^^^^^^
PairFunction cannot be resolved to a type
----------
3. ERROR in \kt0_696d720ab496f3fd.java (at line 162)
	public Tuple2<String, Row> call(final Row arg0) throws Exception {
	                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
The method call(Row) of type new PairFunction<Row,String,Row>(){} must override or implement a supertype method
----------
4. ERROR in \kt0_696d720ab496f3fd.java (at line 166)
	JavaPairRDD<String, Row> pair2 = aInput2.mapToPair(new PairFunction<Row, String, Row>() {
	                                         ^^^^^^^^^
The method mapToPair(PairFunction<Row,K2,V2>) in the type JavaRDD<Row> is not applicable for the arguments (new PairFunction<Row,String,Row>(){})
----------
5. ERROR in \kt0_696d720ab496f3fd.java (at line 166)
	JavaPairRDD<String, Row> pair2 = aInput2.mapToPair(new PairFunction<Row, String, Row>() {
	                                                       ^^^^^^^^^^^^
PairFunction cannot be resolved to a type
----------
6. ERROR in \kt0_696d720ab496f3fd.java (at line 169)
	public Tuple2<String, Row> call(final Row arg0) throws Exception {
	                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
The method call(Row) of type new PairFunction<Row,String,Row>(){} must override or implement a supertype method
----------
6 problems (6 errors)
2015-06-03 15:13:38,673 : DEBUG : KNIME-Worker-7 : JavaCodeCompiler : Spark Snippet : 0:58 : Command line arguments were: [-classpath, C:\DEVELOPMENT\workspaces\trunk\.metadata\.plugins\org.eclipse.pde.core\.bundle_pool\plugins\org.eclipse.equinox.launcher_1.2.0.v20110502.jar;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\lib\job-server-api_2.10-0.5.1-SNAPSHOT.jar;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\bin;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\lib\knimeSparkScalaClient.jar;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\lib\spark-assembly-1.2.1-hadoop2.4.0.jar, -source, 1.7, -target, 1.7, -nowarn]
2015-06-03 15:13:38,674 : DEBUG : KNIME-Worker-7 : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 15:13:38,674 : DEBUG : KNIME-Worker-7 : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 15:13:38,674 : ERROR : KNIME-Worker-7 : Spark Snippet : Spark Snippet : 0:58 : Execute failed: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
PairFunction cannot be resolved to a type

ERROR at line 162
The method call(org.apache.spark.sql.api.java.Row) of type new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){} must override or implement a supertype method

ERROR at line 159
The method mapToPair(org.apache.spark.api.java.function.PairFunction<org.apache.spark.sql.api.java.Row,K2,V2>) in the type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row> is not applicable for the arguments (new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){})

ERROR at line 166
PairFunction cannot be resolved to a type

ERROR at line 169
The method call(org.apache.spark.sql.api.java.Row) of type new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){} must override or implement a supertype method

ERROR at line 166
The method mapToPair(org.apache.spark.api.java.function.PairFunction<org.apache.spark.sql.api.java.Row,K2,V2>) in the type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row> is not applicable for the arguments (new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){})
2015-06-03 15:13:38,674 : DEBUG : KNIME-Worker-7 : Spark Snippet : Spark Snippet : 0:58 : Execute failed: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
PairFunction cannot be resolved to a type

ERROR at line 162
The method call(org.apache.spark.sql.api.java.Row) of type new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){} must override or implement a supertype method

ERROR at line 159
The method mapToPair(org.apache.spark.api.java.function.PairFunction<org.apache.spark.sql.api.java.Row,K2,V2>) in the type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row> is not applicable for the arguments (new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){})

ERROR at line 166
PairFunction cannot be resolved to a type

ERROR at line 169
The method call(org.apache.spark.sql.api.java.Row) of type new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){} must override or implement a supertype method

ERROR at line 166
The method mapToPair(org.apache.spark.api.java.function.PairFunction<org.apache.spark.sql.api.java.Row,K2,V2>) in the type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row> is not applicable for the arguments (new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){})
com.knime.bigdata.spark.jobserver.server.GenericKnimeSparkException: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
PairFunction cannot be resolved to a type

ERROR at line 162
The method call(org.apache.spark.sql.api.java.Row) of type new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){} must override or implement a supertype method

ERROR at line 159
The method mapToPair(org.apache.spark.api.java.function.PairFunction<org.apache.spark.sql.api.java.Row,K2,V2>) in the type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row> is not applicable for the arguments (new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){})

ERROR at line 166
PairFunction cannot be resolved to a type

ERROR at line 169
The method call(org.apache.spark.sql.api.java.Row) of type new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){} must override or implement a supertype method

ERROR at line 166
The method mapToPair(org.apache.spark.api.java.function.PairFunction<org.apache.spark.sql.api.java.Row,K2,V2>) in the type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row> is not applicable for the arguments (new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){})
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler.compileAndCreateInstance(SparkJobCompiler.java:153)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler.addTransformationSparkJob2Jar(SparkJobCompiler.java:115)
	at com.knime.bigdata.spark.node.scripting.snippet.SparkSnippetNodeModel.addTransformationJob2Jar(SparkSnippetNodeModel.java:197)
	at com.knime.bigdata.spark.node.scripting.snippet.SparkSnippetNodeModel.executeInternal(SparkSnippetNodeModel.java:101)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.execute(AbstractSparkNodeModel.java:113)
	at org.knime.core.node.NodeModel.executeModel(NodeModel.java:559)
	at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1134)
	at org.knime.core.node.Node.execute(Node.java:930)
	at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:559)
	at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)
	at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)
	at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)
	at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)
	at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:125)
	at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:248)
Caused by: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
PairFunction cannot be resolved to a type

ERROR at line 162
The method call(org.apache.spark.sql.api.java.Row) of type new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){} must override or implement a supertype method

ERROR at line 159
The method mapToPair(org.apache.spark.api.java.function.PairFunction<org.apache.spark.sql.api.java.Row,K2,V2>) in the type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row> is not applicable for the arguments (new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){})

ERROR at line 166
PairFunction cannot be resolved to a type

ERROR at line 169
The method call(org.apache.spark.sql.api.java.Row) of type new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){} must override or implement a supertype method

ERROR at line 166
The method mapToPair(org.apache.spark.api.java.function.PairFunction<org.apache.spark.sql.api.java.Row,K2,V2>) in the type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row> is not applicable for the arguments (new PairFunction<org.apache.spark.sql.api.java.Row,java.lang.String,org.apache.spark.sql.api.java.Row>(){})
	at org.knime.ext.sun.nodes.script.compile.JavaCodeCompiler.compile(JavaCodeCompiler.java:281)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler$SourceCompiler.compileCode(SparkJobCompiler.java:343)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler$SourceCompiler.setCode(SparkJobCompiler.java:320)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler$SourceCompiler.<init>(SparkJobCompiler.java:296)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler.compileAndCreateInstance(SparkJobCompiler.java:150)
	... 17 more
2015-06-03 15:13:38,675 : DEBUG : KNIME-Worker-7 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforePostExecution
2015-06-03 15:13:38,675 : DEBUG : KNIME-Worker-7 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: POSTEXECUTE
2015-06-03 15:13:38,676 : DEBUG : KNIME-Worker-7 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doAfterExecute - failure
2015-06-03 15:13:38,676 : DEBUG : KNIME-Worker-7 : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 15:13:38,676 : DEBUG : KNIME-Worker-7 : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 15:13:38,676 : DEBUG : KNIME-Worker-7 : Spark Snippet : Spark Snippet : 0:58 : clean output ports.
2015-06-03 15:13:38,676 : DEBUG : KNIME-Worker-7 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:58 : Removing handler 18db94d9-7be0-4153-aab5-3c056a56a5f0 (Spark Snippet 0:58: <no directory>) - 3 remaining
2015-06-03 15:13:38,676 : DEBUG : KNIME-Worker-7 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: IDLE
2015-06-03 15:13:38,677 : DEBUG : KNIME-Worker-7 : Spark Snippet : Spark Snippet : 0:58 : Configure succeeded. (Spark Snippet)
2015-06-03 15:13:38,677 : DEBUG : KNIME-Worker-7 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: CONFIGURED
2015-06-03 15:13:38,677 : DEBUG : KNIME-Worker-7 : NodeContainer : Spark Snippet : 0:58 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 15:14:14,929 : DEBUG : AWT-EventQueue-0 : DataType : Java Snippet : 0:51 : XMLValue is the preferred value class of cell implementation XMLCell, made sanity check
2015-06-03 15:15:43,983 : DEBUG : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforePreExecution
2015-06-03 15:15:43,984 : DEBUG : KNIME-Worker-8 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: PREEXECUTE
2015-06-03 15:15:43,984 : DEBUG : KNIME-Worker-8 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforeExecution
2015-06-03 15:15:43,984 : DEBUG : KNIME-Worker-8 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: EXECUTING
2015-06-03 15:15:43,984 : DEBUG : KNIME-Worker-8 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:58 : Adding handler 76b25381-ac3e-4d6f-8007-1f9e8a7d36c7 (Spark Snippet 0:58: <no directory>) - 4 in total
2015-06-03 15:15:43,984 : DEBUG : KNIME-Worker-8 : LocalNodeExecutionJob : Spark Snippet : 0:58 : Spark Snippet 0:58 Start execute
2015-06-03 15:15:44,106 : DEBUG : KNIME-Worker-8 : JavaCodeCompiler : Spark Snippet : 0:58 : Error output of compilation:
----------
1. ERROR in \kt0_e8ce158e0ddd2c70.java (at line 159)
	public <T extends JavaRDD<Row>> JavaRDD<Row> apply(final T aInput1, final T aInput2) {
	                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
This method must return a result of type JavaRDD<Row>
----------
1 problem (1 error)
2015-06-03 15:15:44,106 : DEBUG : KNIME-Worker-8 : JavaCodeCompiler : Spark Snippet : 0:58 : Command line arguments were: [-classpath, C:\DEVELOPMENT\workspaces\trunk\.metadata\.plugins\org.eclipse.pde.core\.bundle_pool\plugins\org.eclipse.equinox.launcher_1.2.0.v20110502.jar;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\lib\job-server-api_2.10-0.5.1-SNAPSHOT.jar;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\bin;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\lib\knimeSparkScalaClient.jar;C:\DEVELOPMENT\workspaces\trunk\com.knime.bigdata.spark\lib\spark-assembly-1.2.1-hadoop2.4.0.jar, -source, 1.7, -target, 1.7, -nowarn]
2015-06-03 15:15:44,107 : DEBUG : KNIME-Worker-8 : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 15:15:44,107 : DEBUG : KNIME-Worker-8 : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 15:15:44,107 : ERROR : KNIME-Worker-8 : Spark Snippet : Spark Snippet : 0:58 : Execute failed: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
This method must return a result of type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row>
2015-06-03 15:15:44,108 : DEBUG : KNIME-Worker-8 : Spark Snippet : Spark Snippet : 0:58 : Execute failed: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
This method must return a result of type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row>
com.knime.bigdata.spark.jobserver.server.GenericKnimeSparkException: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
This method must return a result of type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row>
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler.compileAndCreateInstance(SparkJobCompiler.java:153)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler.addTransformationSparkJob2Jar(SparkJobCompiler.java:115)
	at com.knime.bigdata.spark.node.scripting.snippet.SparkSnippetNodeModel.addTransformationJob2Jar(SparkSnippetNodeModel.java:197)
	at com.knime.bigdata.spark.node.scripting.snippet.SparkSnippetNodeModel.executeInternal(SparkSnippetNodeModel.java:101)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.execute(AbstractSparkNodeModel.java:113)
	at org.knime.core.node.NodeModel.executeModel(NodeModel.java:559)
	at org.knime.core.node.Node.invokeFullyNodeModelExecute(Node.java:1134)
	at org.knime.core.node.Node.execute(Node.java:930)
	at org.knime.core.node.workflow.NativeNodeContainer.performExecuteNode(NativeNodeContainer.java:559)
	at org.knime.core.node.exec.LocalNodeExecutionJob.mainExecute(LocalNodeExecutionJob.java:95)
	at org.knime.core.node.workflow.NodeExecutionJob.internalRun(NodeExecutionJob.java:179)
	at org.knime.core.node.workflow.NodeExecutionJob.run(NodeExecutionJob.java:110)
	at org.knime.core.util.ThreadUtils$RunnableWithContextImpl.runWithContext(ThreadUtils.java:328)
	at org.knime.core.util.ThreadUtils$RunnableWithContext.run(ThreadUtils.java:204)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at org.knime.core.util.ThreadPool$MyFuture.run(ThreadPool.java:125)
	at org.knime.core.util.ThreadPool$Worker.run(ThreadPool.java:248)
Caused by: org.knime.ext.sun.nodes.script.compile.CompilationFailedException: Unable to compile expression
ERROR at line 159
This method must return a result of type org.apache.spark.api.java.JavaRDD<org.apache.spark.sql.api.java.Row>
	at org.knime.ext.sun.nodes.script.compile.JavaCodeCompiler.compile(JavaCodeCompiler.java:281)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler$SourceCompiler.compileCode(SparkJobCompiler.java:343)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler$SourceCompiler.setCode(SparkJobCompiler.java:320)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler$SourceCompiler.<init>(SparkJobCompiler.java:296)
	at com.knime.bigdata.spark.jobserver.client.jar.SparkJobCompiler.compileAndCreateInstance(SparkJobCompiler.java:150)
	... 17 more
2015-06-03 15:15:44,108 : DEBUG : KNIME-Worker-8 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforePostExecution
2015-06-03 15:15:44,109 : DEBUG : KNIME-Worker-8 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: POSTEXECUTE
2015-06-03 15:15:44,109 : DEBUG : KNIME-Worker-8 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doAfterExecute - failure
2015-06-03 15:15:44,109 : DEBUG : KNIME-Worker-8 : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 15:15:44,109 : DEBUG : KNIME-Worker-8 : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 15:15:44,109 : DEBUG : KNIME-Worker-8 : Spark Snippet : Spark Snippet : 0:58 : clean output ports.
2015-06-03 15:15:44,109 : DEBUG : KNIME-Worker-8 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:58 : Removing handler 76b25381-ac3e-4d6f-8007-1f9e8a7d36c7 (Spark Snippet 0:58: <no directory>) - 3 remaining
2015-06-03 15:15:44,110 : DEBUG : KNIME-Worker-8 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: IDLE
2015-06-03 15:15:44,110 : DEBUG : KNIME-Worker-8 : Spark Snippet : Spark Snippet : 0:58 : Configure succeeded. (Spark Snippet)
2015-06-03 15:15:44,110 : DEBUG : KNIME-Worker-8 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: CONFIGURED
2015-06-03 15:15:44,110 : DEBUG : KNIME-Worker-8 : NodeContainer : Spark Snippet : 0:58 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 15:16:02,986 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 15:16:02,986 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 15:16:02,986 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : clean output ports.
2015-06-03 15:16:02,987 : DEBUG : main : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: IDLE
2015-06-03 15:16:02,987 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : Configure succeeded. (Spark Snippet)
2015-06-03 15:16:02,987 : DEBUG : main : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: CONFIGURED
2015-06-03 15:16:04,831 : DEBUG : KNIME-Worker-9 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforePreExecution
2015-06-03 15:16:04,831 : DEBUG : KNIME-Worker-9 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: PREEXECUTE
2015-06-03 15:16:04,831 : DEBUG : KNIME-Worker-9 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforeExecution
2015-06-03 15:16:04,831 : DEBUG : KNIME-Worker-9 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: EXECUTING
2015-06-03 15:16:04,832 : DEBUG : KNIME-Worker-9 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:58 : Adding handler 08285748-6b91-4ecb-90d9-c68885348472 (Spark Snippet 0:58: <no directory>) - 4 in total
2015-06-03 15:16:04,832 : DEBUG : KNIME-Worker-9 : LocalNodeExecutionJob : Spark Snippet : 0:58 : Spark Snippet 0:58 Start execute
2015-06-03 15:16:06,043 : INFO  : KNIME-Worker-9 : LocalNodeExecutionJob : Spark Snippet : 0:58 : Spark Snippet 0:58 End execute (1 sec)
2015-06-03 15:16:06,043 : DEBUG : KNIME-Worker-9 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforePostExecution
2015-06-03 15:16:06,043 : DEBUG : KNIME-Worker-9 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: POSTEXECUTE
2015-06-03 15:16:06,044 : DEBUG : KNIME-Worker-9 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doAfterExecute - success
2015-06-03 15:16:06,044 : DEBUG : KNIME-Worker-9 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: EXECUTED
2015-06-03 15:16:06,044 : DEBUG : KNIME-Worker-9 : NodeContainer : Spark Snippet : 0:58 : Hive2Spark 0 has new state: CONFIGURED
2015-06-03 15:20:51,778 : ERROR : main : MLlib Predictor : MLlib Predictor : 0:59 : Configure failed (NullPointerException): null
2015-06-03 15:20:51,779 : DEBUG : main : MLlib Predictor : MLlib Predictor : 0:59 : Configure failed (NullPointerException): null
java.lang.NullPointerException
	at org.knime.core.data.DataTableSpec.getUniqueColumnName(DataTableSpec.java:992)
	at com.knime.bigdata.spark.node.mllib.clustering.assigner.MLlibClusterAssignerNodeModel.createSpec(MLlibClusterAssignerNodeModel.java:109)
	at com.knime.bigdata.spark.node.mllib.clustering.assigner.MLlibClusterAssignerNodeModel.configure(MLlibClusterAssignerNodeModel.java:84)
	at org.knime.core.node.NodeModel.configureModel(NodeModel.java:1033)
	at org.knime.core.node.Node.invokeNodeModelConfigure(Node.java:1746)
	at org.knime.core.node.Node.configure(Node.java:1682)
	at org.knime.core.node.workflow.NativeNodeContainer.performConfigure(NativeNodeContainer.java:524)
	at org.knime.core.node.workflow.SingleNodeContainer.callNodeConfigure(SingleNodeContainer.java:282)
	at org.knime.core.node.workflow.SingleNodeContainer.configure(SingleNodeContainer.java:176)
	at org.knime.core.node.workflow.WorkflowManager.configureSingleNodeContainer(WorkflowManager.java:5703)
	at org.knime.core.node.workflow.WorkflowManager.configureNodeAndPortSuccessors(WorkflowManager.java:5861)
	at org.knime.core.node.workflow.WorkflowManager.configureNodeAndSuccessors(WorkflowManager.java:5801)
	at org.knime.core.node.workflow.WorkflowManager.resetAndConfigureNodeAndSuccessors(WorkflowManager.java:4598)
	at org.knime.core.node.workflow.WorkflowManager.resetAndConfigureNode(WorkflowManager.java:4577)
	at org.knime.core.node.workflow.WorkflowManager.addConnection(WorkflowManager.java:935)
	at org.knime.core.node.workflow.WorkflowManager.addConnection(WorkflowManager.java:832)
	at org.knime.workbench.editor2.commands.CreateConnectionCommand.execute(CreateConnectionCommand.java:313)
	at org.eclipse.gef.commands.CommandStack.execute(CommandStack.java:199)
	at org.eclipse.gef.tools.AbstractTool.executeCommand(AbstractTool.java:425)
	at org.eclipse.gef.tools.AbstractTool.executeCurrentCommand(AbstractTool.java:438)
	at org.eclipse.gef.tools.AbstractConnectionCreationTool.handleCreateConnection(AbstractConnectionCreationTool.java:256)
	at org.eclipse.gef.tools.ConnectionDragCreationTool.handleButtonUp(ConnectionDragCreationTool.java:63)
	at org.eclipse.gef.tools.AbstractTool.mouseUp(AbstractTool.java:1200)
	at org.eclipse.gef.tools.SelectionTool.mouseUp(SelectionTool.java:574)
	at org.eclipse.gef.EditDomain.mouseUp(EditDomain.java:301)
	at org.eclipse.gef.ui.parts.DomainEventDispatcher.dispatchMouseReleased(DomainEventDispatcher.java:380)
	at org.eclipse.draw2d.LightweightSystem$EventHandler.mouseUp(LightweightSystem.java:548)
	at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:220)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4353)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1061)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4172)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3761)
	at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2701)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2665)
	at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499)
	at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:134)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1410)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1386)
2015-06-03 15:20:58,759 : ERROR : main : MLlib Predictor : MLlib Predictor : 0:59 : Configure failed (NullPointerException): null
2015-06-03 15:20:58,759 : DEBUG : main : MLlib Predictor : MLlib Predictor : 0:59 : Configure failed (NullPointerException): null
java.lang.NullPointerException
	at org.knime.core.data.DataTableSpec.getUniqueColumnName(DataTableSpec.java:992)
	at com.knime.bigdata.spark.node.mllib.clustering.assigner.MLlibClusterAssignerNodeModel.createSpec(MLlibClusterAssignerNodeModel.java:109)
	at com.knime.bigdata.spark.node.mllib.clustering.assigner.MLlibClusterAssignerNodeModel.configure(MLlibClusterAssignerNodeModel.java:84)
	at org.knime.core.node.NodeModel.configureModel(NodeModel.java:1033)
	at org.knime.core.node.Node.invokeNodeModelConfigure(Node.java:1746)
	at org.knime.core.node.Node.configure(Node.java:1682)
	at org.knime.core.node.workflow.NativeNodeContainer.performConfigure(NativeNodeContainer.java:524)
	at org.knime.core.node.workflow.SingleNodeContainer.callNodeConfigure(SingleNodeContainer.java:282)
	at org.knime.core.node.workflow.SingleNodeContainer.configure(SingleNodeContainer.java:176)
	at org.knime.core.node.workflow.WorkflowManager.configureSingleNodeContainer(WorkflowManager.java:5703)
	at org.knime.core.node.workflow.WorkflowManager.configureNodeAndPortSuccessors(WorkflowManager.java:5861)
	at org.knime.core.node.workflow.WorkflowManager.configureNodeAndSuccessors(WorkflowManager.java:5801)
	at org.knime.core.node.workflow.WorkflowManager.resetAndConfigureNodeAndSuccessors(WorkflowManager.java:4598)
	at org.knime.core.node.workflow.WorkflowManager.resetAndConfigureNode(WorkflowManager.java:4577)
	at org.knime.core.node.workflow.WorkflowManager.addConnection(WorkflowManager.java:935)
	at org.knime.core.node.workflow.WorkflowManager.addConnection(WorkflowManager.java:832)
	at org.knime.workbench.editor2.commands.CreateConnectionCommand.execute(CreateConnectionCommand.java:313)
	at org.eclipse.gef.commands.CommandStack.execute(CommandStack.java:199)
	at org.eclipse.gef.tools.AbstractTool.executeCommand(AbstractTool.java:425)
	at org.eclipse.gef.tools.AbstractTool.executeCurrentCommand(AbstractTool.java:438)
	at org.eclipse.gef.tools.AbstractConnectionCreationTool.handleCreateConnection(AbstractConnectionCreationTool.java:256)
	at org.eclipse.gef.tools.ConnectionDragCreationTool.handleButtonUp(ConnectionDragCreationTool.java:63)
	at org.eclipse.gef.tools.AbstractTool.mouseUp(AbstractTool.java:1200)
	at org.eclipse.gef.tools.SelectionTool.mouseUp(SelectionTool.java:574)
	at org.eclipse.gef.EditDomain.mouseUp(EditDomain.java:301)
	at org.eclipse.gef.ui.parts.DomainEventDispatcher.dispatchMouseReleased(DomainEventDispatcher.java:380)
	at org.eclipse.draw2d.LightweightSystem$EventHandler.mouseUp(LightweightSystem.java:548)
	at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:220)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4353)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1061)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4172)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3761)
	at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2701)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2665)
	at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499)
	at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:134)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1410)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1386)
2015-06-03 15:30:52,252 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : reset
2015-06-03 15:30:52,252 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:58 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 15:30:52,253 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : clean output ports.
2015-06-03 15:30:52,255 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : reset
2015-06-03 15:30:52,255 : DEBUG : main : AbstractSparkNodeModel : Spark Snippet : 0:57 : Entering reset() of class AbstractSparkNodeModel.
2015-06-03 15:30:52,255 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : clean output ports.
2015-06-03 15:30:52,257 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : Configure succeeded. (Spark Snippet)
2015-06-03 15:30:53,100 : DEBUG : KNIME-Worker-10 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doBeforePreExecution
2015-06-03 15:30:53,100 : DEBUG : KNIME-Worker-10 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: PREEXECUTE
2015-06-03 15:30:53,100 : DEBUG : KNIME-Worker-10 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doBeforeExecution
2015-06-03 15:30:53,101 : DEBUG : KNIME-Worker-10 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: EXECUTING
2015-06-03 15:30:53,101 : DEBUG : KNIME-Worker-10 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:57 : Adding handler fd015cbc-4e76-462b-9564-4b30a7657bf5 (Spark Snippet 0:57: <no directory>) - 3 in total
2015-06-03 15:30:53,101 : DEBUG : KNIME-Worker-10 : LocalNodeExecutionJob : Spark Snippet : 0:57 : Spark Snippet 0:57 Start execute
2015-06-03 15:30:54,293 : INFO  : KNIME-Worker-10 : LocalNodeExecutionJob : Spark Snippet : 0:57 : Spark Snippet 0:57 End execute (1 sec)
2015-06-03 15:30:54,294 : DEBUG : KNIME-Worker-10 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doBeforePostExecution
2015-06-03 15:30:54,294 : DEBUG : KNIME-Worker-10 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: POSTEXECUTE
2015-06-03 15:30:54,294 : DEBUG : KNIME-Worker-10 : WorkflowManager : Spark Snippet : 0:57 : Spark Snippet 0:57 doAfterExecute - success
2015-06-03 15:30:54,295 : DEBUG : KNIME-Worker-10 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:57 has new state: EXECUTED
2015-06-03 15:30:54,295 : DEBUG : KNIME-Worker-10 : Spark Snippet : Spark Snippet : 0:58 : Configure succeeded. (Spark Snippet)
2015-06-03 15:30:54,295 : DEBUG : KNIME-Worker-10 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:58 has new state: CONFIGURED_MARKEDFOREXEC
2015-06-03 15:30:54,295 : DEBUG : KNIME-Worker-10 : NodeContainer : Spark Snippet : 0:57 : Spark Snippet 0:58 has new state: CONFIGURED_QUEUED
2015-06-03 15:30:54,296 : DEBUG : KNIME-Worker-11 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforePreExecution
2015-06-03 15:30:54,296 : DEBUG : KNIME-Worker-11 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: PREEXECUTE
2015-06-03 15:30:54,296 : DEBUG : KNIME-Worker-11 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforeExecution
2015-06-03 15:30:54,296 : DEBUG : KNIME-Worker-11 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: EXECUTING
2015-06-03 15:30:54,296 : DEBUG : KNIME-Worker-11 : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:58 : Adding handler 492601ab-1e9b-4e9a-b8e0-388bbe9246cd (Spark Snippet 0:58: <no directory>) - 4 in total
2015-06-03 15:30:54,297 : DEBUG : KNIME-Worker-11 : LocalNodeExecutionJob : Spark Snippet : 0:58 : Spark Snippet 0:58 Start execute
2015-06-03 15:30:55,523 : INFO  : KNIME-Worker-11 : LocalNodeExecutionJob : Spark Snippet : 0:58 : Spark Snippet 0:58 End execute (1 sec)
2015-06-03 15:30:55,524 : DEBUG : KNIME-Worker-11 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doBeforePostExecution
2015-06-03 15:30:55,524 : DEBUG : KNIME-Worker-11 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: POSTEXECUTE
2015-06-03 15:30:55,524 : DEBUG : KNIME-Worker-11 : WorkflowManager : Spark Snippet : 0:58 : Spark Snippet 0:58 doAfterExecute - success
2015-06-03 15:30:55,524 : DEBUG : KNIME-Worker-11 : NodeContainer : Spark Snippet : 0:58 : Spark Snippet 0:58 has new state: EXECUTED
2015-06-03 15:30:55,524 : DEBUG : KNIME-Worker-11 : NodeContainer : Spark Snippet : 0:58 : Hive2Spark 0 has new state: IDLE
2015-06-03 15:38:02,412 : DEBUG : main : MLlibClusterAssignerNodeModel : MLlib Predictor : 0:59 : Removing all (0) views from model.
2015-06-03 15:38:02,412 : DEBUG : main : MLlib Predictor : MLlib Predictor : 0:59 : clean output ports.
2015-06-03 15:38:02,413 : DEBUG : main : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:58 : Removing handler 492601ab-1e9b-4e9a-b8e0-388bbe9246cd (Spark Snippet 0:58: <no directory>) - 3 remaining
2015-06-03 15:38:02,413 : DEBUG : main : SparkSnippetNodeModel : Spark Snippet : 0:58 : Removing all (0) views from model.
2015-06-03 15:38:02,413 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : clean output ports.
2015-06-03 15:38:02,413 : DEBUG : main : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:57 : Removing handler fd015cbc-4e76-462b-9564-4b30a7657bf5 (Spark Snippet 0:57: <no directory>) - 2 remaining
2015-06-03 15:38:02,413 : DEBUG : main : SparkSnippetNodeModel : Spark Snippet : 0:57 : Removing all (0) views from model.
2015-06-03 15:38:02,413 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : clean output ports.
2015-06-03 15:38:02,414 : DEBUG : main : MLlibKMeansNodeModel : MLlib k-Means : 0:50 : Removing all (0) views from model.
2015-06-03 15:38:02,414 : DEBUG : main : MLlib k-Means : MLlib k-Means : 0:50 : clean output ports.
2015-06-03 15:38:02,414 : DEBUG : main : WorkflowFileStoreHandlerRepository : Spark Snippet : 0:52 : Removing handler 069f0513-f4c2-44af-8093-c2753d6ca252 (Spark Snippet 0:52: <no directory>) - 1 remaining
2015-06-03 15:38:02,414 : DEBUG : main : SparkSnippetNodeModel : Spark Snippet : 0:52 : Removing all (0) views from model.
2015-06-03 15:38:02,414 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : clean output ports.
2015-06-03 15:38:02,414 : DEBUG : main : GroupByNodeModel : GroupBy : 0:54 : Removing all (0) views from model.
2015-06-03 15:38:02,415 : DEBUG : main : GroupBy : GroupBy : 0:54 : clean output ports.
2015-06-03 15:38:02,415 : DEBUG : main : WorkflowFileStoreHandlerRepository : Hive to Spark : 0:49 : Removing handler 804b4e56-7e93-4090-b387-826a4e64c39b (Hive to Spark 0:49: <no directory>) - 0 remaining
2015-06-03 15:38:02,415 : DEBUG : main : Hive2SparkNodeModel : Hive to Spark : 0:49 : Removing all (0) views from model.
2015-06-03 15:38:02,415 : DEBUG : main : Hive to Spark : Hive to Spark : 0:49 : clean output ports.
2015-06-03 15:38:02,416 : DEBUG : main : DBTableSelectorNodeModel : Database Table Selector : 0:43 : Removing all (0) views from model.
2015-06-03 15:38:02,416 : DEBUG : main : Database Table Selector : Database Table Selector : 0:43 : clean output ports.
2015-06-03 15:38:02,416 : DEBUG : main : LinReg2LearnerNodeModel : Linear Regression Learner : 0:56 : Removing all (0) views from model.
2015-06-03 15:38:02,417 : DEBUG : main : Linear Regression Learner : Linear Regression Learner : 0:56 : clean output ports.
2015-06-03 15:38:02,417 : DEBUG : main : JavaSnippetNodeModel : Java Snippet : 0:51 : Removing all (0) views from model.
2015-06-03 15:38:02,417 : DEBUG : main : Java Snippet : Java Snippet : 0:51 : clean output ports.
2015-06-03 15:38:02,418 : DEBUG : main : HiveLoaderNodeModel : Hive Loader : 0:46 : Removing all (0) views from model.
2015-06-03 15:38:02,418 : DEBUG : main : Hive Loader : Hive Loader : 0:46 : clean output ports.
2015-06-03 15:38:02,419 : DEBUG : main : DBSQLExecutorNodeModel : Database SQL Executor : 0:42 : Removing all (0) views from model.
2015-06-03 15:38:02,419 : DEBUG : main : Database SQL Executor : Database SQL Executor : 0:42 : clean output ports.
2015-06-03 15:38:02,420 : DEBUG : main : FileReaderNodeModel : File Reader : 0:55 : Removing all (0) views from model.
2015-06-03 15:38:02,420 : DEBUG : main : File Reader : File Reader : 0:55 : clean output ports.
2015-06-03 15:38:02,421 : DEBUG : main : ConnectionInformationNodeModel : SSH Connection : 0:48 : Removing all (0) views from model.
2015-06-03 15:38:02,421 : DEBUG : main : SSH Connection : SSH Connection : 0:48 : clean output ports.
2015-06-03 15:38:02,421 : DEBUG : main : FileReaderNodeModel : File Reader : 0:44 : Removing all (0) views from model.
2015-06-03 15:38:02,421 : DEBUG : main : File Reader : File Reader : 0:44 : clean output ports.
2015-06-03 15:38:02,422 : DEBUG : main : HiveConnectorNodeModel : Hive Connector : 0:1 : Removing all (0) views from model.
2015-06-03 15:38:02,422 : DEBUG : main : Hive Connector : Hive Connector : 0:1 : clean output ports.
2015-06-03 18:01:59,622 : DEBUG : main : HiveConnectorNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:07,310 : DEBUG : main : DBSQLExecutorNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:35,533 : DEBUG : main : DBTableSelectorNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:37,799 : DEBUG : main : FileReaderNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:37,908 : DEBUG : main : HiveLoaderNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:37,955 : DEBUG : main : SSHConnectionInformationNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:37,971 : DEBUG : main : Hive2SparkNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:38,002 : DEBUG : main : MLlibKMeansNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:38,017 : DEBUG : main : JavaSnippetNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:38,049 : DEBUG : main : SparkSnippetNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:38,064 : DEBUG : main : GroupByNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:38,080 : DEBUG : main : FileReaderNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:38,096 : DEBUG : main : LinReg2LearnerNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:38,111 : DEBUG : main : SparkSnippetNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:38,111 : DEBUG : main : SparkSnippetNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:38,127 : DEBUG : main : MLlibClusterAssignerNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:02:38,158 : DEBUG : main : DataType : File Reader : 0:44 : DoubleValue is the preferred value class of cell implementation DoubleCell, made sanity check
2015-06-03 18:02:38,158 : DEBUG : main : DataType : File Reader : 0:44 : StringValue is the preferred value class of cell implementation StringCell, made sanity check
2015-06-03 18:02:38,189 : DEBUG : main : File Reader : File Reader : 0:55 : Configure succeeded. (File Reader)
2015-06-03 18:02:38,611 : DEBUG : main : Java Snippet : Java Snippet : 0:51 : Configure succeeded. (Java Snippet)
2015-06-03 18:02:38,627 : DEBUG : main : Linear Regression Learner : Linear Regression Learner : 0:56 : Configure succeeded. (Linear Regression Learner)
2015-06-03 18:02:38,642 : DEBUG : main : DataType : Database Table Selector : 0:43 : IntValue is the preferred value class of cell implementation IntCell, made sanity check
2015-06-03 18:02:38,658 : DEBUG : main : DataType : GroupBy : 0:54 : DateAndTimeValue is the preferred value class of cell implementation DateAndTimeCell, made sanity check
2015-06-03 18:02:38,658 : DEBUG : main : DataType : GroupBy : 0:54 : LongValue is the preferred value class of cell implementation LongCell, made sanity check
2015-06-03 18:02:38,674 : DEBUG : main : DataType : GroupBy : 0:54 : BitVectorValue is the preferred value class of cell implementation DenseBitVectorCell, made sanity check
2015-06-03 18:02:38,674 : WARN  : main : GroupBy : GroupBy : 0:54 : No grouping column included. Aggregate complete table.
2015-06-03 18:02:38,687 : DEBUG : main : GroupByNodeModel : GroupBy : 0:54 : [sepal width->Sum false]
2015-06-03 18:02:38,688 : DEBUG : main : GroupBy : GroupBy : 0:54 : Configure succeeded. (GroupBy)
2015-06-03 18:03:00,349 : DEBUG : main : Hive to Spark : Hive to Spark : 0:49 : Loading model internals failed: Failed to load named rdd
java.io.IOException: Failed to load named rdd
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:188)
	at org.knime.core.node.Node.loadDataAndInternals(Node.java:465)
	at org.knime.core.node.Node.load(Node.java:326)
	at org.knime.core.node.FileNodePersistor.load(FileNodePersistor.java:1037)
	at org.knime.core.node.workflow.FileNativeNodeContainerPersistor.loadNCAndWashModelSettings(FileNativeNodeContainerPersistor.java:272)
	at org.knime.core.node.workflow.FileSingleNodeContainerPersistor.loadNodeContainer(FileSingleNodeContainerPersistor.java:270)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7535)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7553)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7379)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7304)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7277)
	at org.knime.core.node.workflow.WorkflowManager.loadProject(WorkflowManager.java:7115)
	at org.knime.workbench.editor2.LoadWorkflowRunnable.run(LoadWorkflowRunnable.java:154)
	at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:464)
	at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:372)
	at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:507)
	at org.eclipse.ui.internal.progress.ProgressMonitorJobsDialog.run(ProgressMonitorJobsDialog.java:275)
	at org.eclipse.ui.internal.progress.ProgressManager$5.run(ProgressManager.java:960)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:995)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:970)
	at org.knime.workbench.editor2.WorkflowEditor.setInput(WorkflowEditor.java:1093)
	at org.knime.workbench.editor2.WorkflowEditor.init(WorkflowEditor.java:405)
	at org.eclipse.ui.internal.EditorManager.createSite(EditorManager.java:828)
	at org.eclipse.ui.internal.EditorReference.createPartHelper(EditorReference.java:647)
	at org.eclipse.ui.internal.EditorReference.createPart(EditorReference.java:465)
	at org.eclipse.ui.internal.WorkbenchPartReference.getPart(WorkbenchPartReference.java:595)
	at org.eclipse.ui.internal.EditorAreaHelper.setVisibleEditor(EditorAreaHelper.java:271)
	at org.eclipse.ui.internal.EditorManager.setVisibleEditor(EditorManager.java:1459)
	at org.eclipse.ui.internal.EditorManager$5.runWithException(EditorManager.java:972)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:803)
	at org.eclipse.ui.internal.Workbench$33.runWithException(Workbench.java:1600)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2609)
	at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499)
	at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:134)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1410)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1386)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1300)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.glassfish.jersey.client.HttpUrlConnector._apply(HttpUrlConnector.java:335)
	at org.glassfish.jersey.client.HttpUrlConnector.apply(HttpUrlConnector.java:242)
	at org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:245)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:671)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:668)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:228)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:444)
	at org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:668)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:402)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.get(JerseyInvocation.java:302)
	at com.knime.bigdata.spark.jobserver.client.WsRsRestClient.toJSONArray(WsRsRestClient.java:125)
	at com.knime.bigdata.spark.jobserver.client.RestClient.toJSONArray(RestClient.java:80)
	at com.knime.bigdata.spark.jobserver.client.KnimeContext.sparkContextExists(KnimeContext.java:70)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:181)
	... 63 more
2015-06-03 18:03:21,396 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : Loading model internals failed: Failed to load named rdd
java.io.IOException: Failed to load named rdd
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:188)
	at org.knime.core.node.Node.loadDataAndInternals(Node.java:465)
	at org.knime.core.node.Node.load(Node.java:326)
	at org.knime.core.node.FileNodePersistor.load(FileNodePersistor.java:1037)
	at org.knime.core.node.workflow.FileNativeNodeContainerPersistor.loadNCAndWashModelSettings(FileNativeNodeContainerPersistor.java:272)
	at org.knime.core.node.workflow.FileSingleNodeContainerPersistor.loadNodeContainer(FileSingleNodeContainerPersistor.java:270)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7535)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7553)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7379)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7304)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7277)
	at org.knime.core.node.workflow.WorkflowManager.loadProject(WorkflowManager.java:7115)
	at org.knime.workbench.editor2.LoadWorkflowRunnable.run(LoadWorkflowRunnable.java:154)
	at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:464)
	at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:372)
	at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:507)
	at org.eclipse.ui.internal.progress.ProgressMonitorJobsDialog.run(ProgressMonitorJobsDialog.java:275)
	at org.eclipse.ui.internal.progress.ProgressManager$5.run(ProgressManager.java:960)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:995)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:970)
	at org.knime.workbench.editor2.WorkflowEditor.setInput(WorkflowEditor.java:1093)
	at org.knime.workbench.editor2.WorkflowEditor.init(WorkflowEditor.java:405)
	at org.eclipse.ui.internal.EditorManager.createSite(EditorManager.java:828)
	at org.eclipse.ui.internal.EditorReference.createPartHelper(EditorReference.java:647)
	at org.eclipse.ui.internal.EditorReference.createPart(EditorReference.java:465)
	at org.eclipse.ui.internal.WorkbenchPartReference.getPart(WorkbenchPartReference.java:595)
	at org.eclipse.ui.internal.EditorAreaHelper.setVisibleEditor(EditorAreaHelper.java:271)
	at org.eclipse.ui.internal.EditorManager.setVisibleEditor(EditorManager.java:1459)
	at org.eclipse.ui.internal.EditorManager$5.runWithException(EditorManager.java:972)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:803)
	at org.eclipse.ui.internal.Workbench$33.runWithException(Workbench.java:1600)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2609)
	at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499)
	at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:134)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1410)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1386)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1300)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.glassfish.jersey.client.HttpUrlConnector._apply(HttpUrlConnector.java:335)
	at org.glassfish.jersey.client.HttpUrlConnector.apply(HttpUrlConnector.java:242)
	at org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:245)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:671)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:668)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:228)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:444)
	at org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:668)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:402)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.get(JerseyInvocation.java:302)
	at com.knime.bigdata.spark.jobserver.client.WsRsRestClient.toJSONArray(WsRsRestClient.java:125)
	at com.knime.bigdata.spark.jobserver.client.RestClient.toJSONArray(RestClient.java:80)
	at com.knime.bigdata.spark.jobserver.client.KnimeContext.sparkContextExists(KnimeContext.java:70)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:181)
	... 63 more
2015-06-03 18:03:21,396 : DEBUG : main : MLlib k-Means : MLlib k-Means : 0:50 : Configure succeeded. (MLlib k-Means)
2015-06-03 18:03:42,428 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : Loading model internals failed: Failed to load named rdd
java.io.IOException: Failed to load named rdd
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:188)
	at org.knime.core.node.Node.loadDataAndInternals(Node.java:465)
	at org.knime.core.node.Node.load(Node.java:326)
	at org.knime.core.node.FileNodePersistor.load(FileNodePersistor.java:1037)
	at org.knime.core.node.workflow.FileNativeNodeContainerPersistor.loadNCAndWashModelSettings(FileNativeNodeContainerPersistor.java:272)
	at org.knime.core.node.workflow.FileSingleNodeContainerPersistor.loadNodeContainer(FileSingleNodeContainerPersistor.java:270)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7535)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7553)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7379)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7304)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7277)
	at org.knime.core.node.workflow.WorkflowManager.loadProject(WorkflowManager.java:7115)
	at org.knime.workbench.editor2.LoadWorkflowRunnable.run(LoadWorkflowRunnable.java:154)
	at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:464)
	at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:372)
	at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:507)
	at org.eclipse.ui.internal.progress.ProgressMonitorJobsDialog.run(ProgressMonitorJobsDialog.java:275)
	at org.eclipse.ui.internal.progress.ProgressManager$5.run(ProgressManager.java:960)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:995)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:970)
	at org.knime.workbench.editor2.WorkflowEditor.setInput(WorkflowEditor.java:1093)
	at org.knime.workbench.editor2.WorkflowEditor.init(WorkflowEditor.java:405)
	at org.eclipse.ui.internal.EditorManager.createSite(EditorManager.java:828)
	at org.eclipse.ui.internal.EditorReference.createPartHelper(EditorReference.java:647)
	at org.eclipse.ui.internal.EditorReference.createPart(EditorReference.java:465)
	at org.eclipse.ui.internal.WorkbenchPartReference.getPart(WorkbenchPartReference.java:595)
	at org.eclipse.ui.internal.EditorAreaHelper.setVisibleEditor(EditorAreaHelper.java:271)
	at org.eclipse.ui.internal.EditorManager.setVisibleEditor(EditorManager.java:1459)
	at org.eclipse.ui.internal.EditorManager$5.runWithException(EditorManager.java:972)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:803)
	at org.eclipse.ui.internal.Workbench$33.runWithException(Workbench.java:1600)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2609)
	at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499)
	at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:134)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1410)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1386)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1300)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.glassfish.jersey.client.HttpUrlConnector._apply(HttpUrlConnector.java:335)
	at org.glassfish.jersey.client.HttpUrlConnector.apply(HttpUrlConnector.java:242)
	at org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:245)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:671)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:668)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:228)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:444)
	at org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:668)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:402)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.get(JerseyInvocation.java:302)
	at com.knime.bigdata.spark.jobserver.client.WsRsRestClient.toJSONArray(WsRsRestClient.java:125)
	at com.knime.bigdata.spark.jobserver.client.RestClient.toJSONArray(RestClient.java:80)
	at com.knime.bigdata.spark.jobserver.client.KnimeContext.sparkContextExists(KnimeContext.java:70)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:181)
	... 63 more
2015-06-03 18:04:11,730 : DEBUG : main : HiveConnectorNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,808 : DEBUG : main : DBSQLExecutorNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,824 : DEBUG : main : DBTableSelectorNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,839 : DEBUG : main : FileReaderNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,855 : DEBUG : main : HiveLoaderNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,886 : DEBUG : main : SSHConnectionInformationNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,886 : DEBUG : main : Hive2SparkNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,902 : DEBUG : main : MLlibKMeansNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,933 : DEBUG : main : JavaSnippetNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,949 : DEBUG : main : SparkSnippetNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,964 : DEBUG : main : GroupByNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,980 : DEBUG : main : FileReaderNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,996 : DEBUG : main : LinReg2LearnerNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:11,996 : DEBUG : main : SparkSnippetNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:12,011 : DEBUG : main : SparkSnippetNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:12,011 : DEBUG : main : MLlibClusterAssignerNodeFactory : Hive2Spark : 0 : Factory is already initialized. Nothing to do.
2015-06-03 18:04:12,058 : DEBUG : main : DataType : File Reader : 0:44 : DoubleValue is the preferred value class of cell implementation DoubleCell, made sanity check
2015-06-03 18:04:12,058 : DEBUG : main : DataType : File Reader : 0:44 : StringValue is the preferred value class of cell implementation StringCell, made sanity check
2015-06-03 18:04:12,089 : DEBUG : main : File Reader : File Reader : 0:55 : Configure succeeded. (File Reader)
2015-06-03 18:04:12,496 : DEBUG : main : Java Snippet : Java Snippet : 0:51 : Configure succeeded. (Java Snippet)
2015-06-03 18:04:12,527 : DEBUG : main : Linear Regression Learner : Linear Regression Learner : 0:56 : Configure succeeded. (Linear Regression Learner)
2015-06-03 18:04:12,527 : DEBUG : main : DataType : Database Table Selector : 0:43 : IntValue is the preferred value class of cell implementation IntCell, made sanity check
2015-06-03 18:04:12,558 : DEBUG : main : DataType : GroupBy : 0:54 : DateAndTimeValue is the preferred value class of cell implementation DateAndTimeCell, made sanity check
2015-06-03 18:04:12,558 : DEBUG : main : DataType : GroupBy : 0:54 : LongValue is the preferred value class of cell implementation LongCell, made sanity check
2015-06-03 18:04:12,558 : DEBUG : main : DataType : GroupBy : 0:54 : BitVectorValue is the preferred value class of cell implementation DenseBitVectorCell, made sanity check
2015-06-03 18:04:12,574 : WARN  : main : GroupBy : GroupBy : 0:54 : No grouping column included. Aggregate complete table.
2015-06-03 18:04:12,577 : DEBUG : main : GroupByNodeModel : GroupBy : 0:54 : [sepal width->Sum false]
2015-06-03 18:04:12,578 : DEBUG : main : GroupBy : GroupBy : 0:54 : Configure succeeded. (GroupBy)
2015-06-03 18:04:34,219 : DEBUG : main : Hive to Spark : Hive to Spark : 0:49 : Loading model internals failed: Failed to load named rdd
java.io.IOException: Failed to load named rdd
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:188)
	at org.knime.core.node.Node.loadDataAndInternals(Node.java:465)
	at org.knime.core.node.Node.load(Node.java:326)
	at org.knime.core.node.FileNodePersistor.load(FileNodePersistor.java:1037)
	at org.knime.core.node.workflow.FileNativeNodeContainerPersistor.loadNCAndWashModelSettings(FileNativeNodeContainerPersistor.java:272)
	at org.knime.core.node.workflow.FileSingleNodeContainerPersistor.loadNodeContainer(FileSingleNodeContainerPersistor.java:270)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7535)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7553)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7379)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7304)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7277)
	at org.knime.core.node.workflow.WorkflowManager.loadProject(WorkflowManager.java:7115)
	at org.knime.workbench.editor2.LoadWorkflowRunnable.run(LoadWorkflowRunnable.java:154)
	at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:464)
	at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:372)
	at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:507)
	at org.eclipse.ui.internal.progress.ProgressMonitorJobsDialog.run(ProgressMonitorJobsDialog.java:275)
	at org.eclipse.ui.internal.progress.ProgressManager$5.run(ProgressManager.java:960)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:995)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:970)
	at org.knime.workbench.editor2.WorkflowEditor.setInput(WorkflowEditor.java:1093)
	at org.knime.workbench.editor2.WorkflowEditor.init(WorkflowEditor.java:405)
	at org.eclipse.ui.internal.EditorManager.createSite(EditorManager.java:828)
	at org.eclipse.ui.internal.EditorReference.createPartHelper(EditorReference.java:647)
	at org.eclipse.ui.internal.EditorReference.createPart(EditorReference.java:465)
	at org.eclipse.ui.internal.WorkbenchPartReference.getPart(WorkbenchPartReference.java:595)
	at org.eclipse.ui.internal.EditorAreaHelper.setVisibleEditor(EditorAreaHelper.java:271)
	at org.eclipse.ui.internal.EditorManager.setVisibleEditor(EditorManager.java:1459)
	at org.eclipse.ui.internal.EditorManager$5.runWithException(EditorManager.java:972)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:803)
	at org.eclipse.ui.internal.Workbench$33.runWithException(Workbench.java:1600)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2609)
	at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499)
	at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:134)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1410)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1386)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1300)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.glassfish.jersey.client.HttpUrlConnector._apply(HttpUrlConnector.java:335)
	at org.glassfish.jersey.client.HttpUrlConnector.apply(HttpUrlConnector.java:242)
	at org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:245)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:671)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:668)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:228)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:444)
	at org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:668)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:402)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.get(JerseyInvocation.java:302)
	at com.knime.bigdata.spark.jobserver.client.WsRsRestClient.toJSONArray(WsRsRestClient.java:125)
	at com.knime.bigdata.spark.jobserver.client.RestClient.toJSONArray(RestClient.java:80)
	at com.knime.bigdata.spark.jobserver.client.KnimeContext.sparkContextExists(KnimeContext.java:70)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:181)
	... 63 more
2015-06-03 18:04:55,251 : DEBUG : main : Spark Snippet : Spark Snippet : 0:52 : Loading model internals failed: Failed to load named rdd
java.io.IOException: Failed to load named rdd
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:188)
	at org.knime.core.node.Node.loadDataAndInternals(Node.java:465)
	at org.knime.core.node.Node.load(Node.java:326)
	at org.knime.core.node.FileNodePersistor.load(FileNodePersistor.java:1037)
	at org.knime.core.node.workflow.FileNativeNodeContainerPersistor.loadNCAndWashModelSettings(FileNativeNodeContainerPersistor.java:272)
	at org.knime.core.node.workflow.FileSingleNodeContainerPersistor.loadNodeContainer(FileSingleNodeContainerPersistor.java:270)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7535)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7553)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7379)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7304)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7277)
	at org.knime.core.node.workflow.WorkflowManager.loadProject(WorkflowManager.java:7115)
	at org.knime.workbench.editor2.LoadWorkflowRunnable.run(LoadWorkflowRunnable.java:154)
	at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:464)
	at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:372)
	at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:507)
	at org.eclipse.ui.internal.progress.ProgressMonitorJobsDialog.run(ProgressMonitorJobsDialog.java:275)
	at org.eclipse.ui.internal.progress.ProgressManager$5.run(ProgressManager.java:960)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:995)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:970)
	at org.knime.workbench.editor2.WorkflowEditor.setInput(WorkflowEditor.java:1093)
	at org.knime.workbench.editor2.WorkflowEditor.init(WorkflowEditor.java:405)
	at org.eclipse.ui.internal.EditorManager.createSite(EditorManager.java:828)
	at org.eclipse.ui.internal.EditorReference.createPartHelper(EditorReference.java:647)
	at org.eclipse.ui.internal.EditorReference.createPart(EditorReference.java:465)
	at org.eclipse.ui.internal.WorkbenchPartReference.getPart(WorkbenchPartReference.java:595)
	at org.eclipse.ui.internal.EditorAreaHelper.setVisibleEditor(EditorAreaHelper.java:271)
	at org.eclipse.ui.internal.EditorManager.setVisibleEditor(EditorManager.java:1459)
	at org.eclipse.ui.internal.EditorManager$5.runWithException(EditorManager.java:972)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:803)
	at org.eclipse.ui.internal.Workbench$33.runWithException(Workbench.java:1600)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2609)
	at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499)
	at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:134)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1410)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1386)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1300)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.glassfish.jersey.client.HttpUrlConnector._apply(HttpUrlConnector.java:335)
	at org.glassfish.jersey.client.HttpUrlConnector.apply(HttpUrlConnector.java:242)
	at org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:245)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:671)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:668)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:228)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:444)
	at org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:668)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:402)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.get(JerseyInvocation.java:302)
	at com.knime.bigdata.spark.jobserver.client.WsRsRestClient.toJSONArray(WsRsRestClient.java:125)
	at com.knime.bigdata.spark.jobserver.client.RestClient.toJSONArray(RestClient.java:80)
	at com.knime.bigdata.spark.jobserver.client.KnimeContext.sparkContextExists(KnimeContext.java:70)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:181)
	... 63 more
2015-06-03 18:04:55,251 : DEBUG : main : MLlib k-Means : MLlib k-Means : 0:50 : Configure succeeded. (MLlib k-Means)
2015-06-03 18:05:16,298 : DEBUG : main : Spark Snippet : Spark Snippet : 0:57 : Loading model internals failed: Failed to load named rdd
java.io.IOException: Failed to load named rdd
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:188)
	at org.knime.core.node.Node.loadDataAndInternals(Node.java:465)
	at org.knime.core.node.Node.load(Node.java:326)
	at org.knime.core.node.FileNodePersistor.load(FileNodePersistor.java:1037)
	at org.knime.core.node.workflow.FileNativeNodeContainerPersistor.loadNCAndWashModelSettings(FileNativeNodeContainerPersistor.java:272)
	at org.knime.core.node.workflow.FileSingleNodeContainerPersistor.loadNodeContainer(FileSingleNodeContainerPersistor.java:270)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7535)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7553)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7379)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7304)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7277)
	at org.knime.core.node.workflow.WorkflowManager.loadProject(WorkflowManager.java:7115)
	at org.knime.workbench.editor2.LoadWorkflowRunnable.run(LoadWorkflowRunnable.java:154)
	at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:464)
	at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:372)
	at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:507)
	at org.eclipse.ui.internal.progress.ProgressMonitorJobsDialog.run(ProgressMonitorJobsDialog.java:275)
	at org.eclipse.ui.internal.progress.ProgressManager$5.run(ProgressManager.java:960)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:995)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:970)
	at org.knime.workbench.editor2.WorkflowEditor.setInput(WorkflowEditor.java:1093)
	at org.knime.workbench.editor2.WorkflowEditor.init(WorkflowEditor.java:405)
	at org.eclipse.ui.internal.EditorManager.createSite(EditorManager.java:828)
	at org.eclipse.ui.internal.EditorReference.createPartHelper(EditorReference.java:647)
	at org.eclipse.ui.internal.EditorReference.createPart(EditorReference.java:465)
	at org.eclipse.ui.internal.WorkbenchPartReference.getPart(WorkbenchPartReference.java:595)
	at org.eclipse.ui.internal.EditorAreaHelper.setVisibleEditor(EditorAreaHelper.java:271)
	at org.eclipse.ui.internal.EditorManager.setVisibleEditor(EditorManager.java:1459)
	at org.eclipse.ui.internal.EditorManager$5.runWithException(EditorManager.java:972)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:803)
	at org.eclipse.ui.internal.Workbench$33.runWithException(Workbench.java:1600)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2609)
	at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499)
	at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:134)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1410)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1386)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1300)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.glassfish.jersey.client.HttpUrlConnector._apply(HttpUrlConnector.java:335)
	at org.glassfish.jersey.client.HttpUrlConnector.apply(HttpUrlConnector.java:242)
	at org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:245)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:671)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:668)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:228)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:444)
	at org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:668)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:402)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.get(JerseyInvocation.java:302)
	at com.knime.bigdata.spark.jobserver.client.WsRsRestClient.toJSONArray(WsRsRestClient.java:125)
	at com.knime.bigdata.spark.jobserver.client.RestClient.toJSONArray(RestClient.java:80)
	at com.knime.bigdata.spark.jobserver.client.KnimeContext.sparkContextExists(KnimeContext.java:70)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:181)
	... 63 more
2015-06-03 18:05:37,314 : DEBUG : main : Spark Snippet : Spark Snippet : 0:58 : Loading model internals failed: Failed to load named rdd
java.io.IOException: Failed to load named rdd
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:188)
	at org.knime.core.node.Node.loadDataAndInternals(Node.java:465)
	at org.knime.core.node.Node.load(Node.java:326)
	at org.knime.core.node.FileNodePersistor.load(FileNodePersistor.java:1037)
	at org.knime.core.node.workflow.FileNativeNodeContainerPersistor.loadNCAndWashModelSettings(FileNativeNodeContainerPersistor.java:272)
	at org.knime.core.node.workflow.FileSingleNodeContainerPersistor.loadNodeContainer(FileSingleNodeContainerPersistor.java:270)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7535)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7553)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7379)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7304)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7277)
	at org.knime.core.node.workflow.WorkflowManager.loadProject(WorkflowManager.java:7115)
	at org.knime.workbench.editor2.LoadWorkflowRunnable.run(LoadWorkflowRunnable.java:154)
	at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:464)
	at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:372)
	at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:507)
	at org.eclipse.ui.internal.progress.ProgressMonitorJobsDialog.run(ProgressMonitorJobsDialog.java:275)
	at org.eclipse.ui.internal.progress.ProgressManager$5.run(ProgressManager.java:960)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:995)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:970)
	at org.knime.workbench.editor2.WorkflowEditor.setInput(WorkflowEditor.java:1093)
	at org.knime.workbench.editor2.WorkflowEditor.init(WorkflowEditor.java:405)
	at org.eclipse.ui.internal.EditorManager.createSite(EditorManager.java:828)
	at org.eclipse.ui.internal.EditorReference.createPartHelper(EditorReference.java:647)
	at org.eclipse.ui.internal.EditorReference.createPart(EditorReference.java:465)
	at org.eclipse.ui.internal.WorkbenchPartReference.getPart(WorkbenchPartReference.java:595)
	at org.eclipse.ui.internal.EditorAreaHelper.setVisibleEditor(EditorAreaHelper.java:271)
	at org.eclipse.ui.internal.EditorManager.setVisibleEditor(EditorManager.java:1459)
	at org.eclipse.ui.internal.EditorManager$5.runWithException(EditorManager.java:972)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:803)
	at org.eclipse.ui.internal.Workbench$33.runWithException(Workbench.java:1600)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2609)
	at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499)
	at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:134)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1410)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1386)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1300)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.glassfish.jersey.client.HttpUrlConnector._apply(HttpUrlConnector.java:335)
	at org.glassfish.jersey.client.HttpUrlConnector.apply(HttpUrlConnector.java:242)
	at org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:245)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:671)
	at org.glassfish.jersey.client.JerseyInvocation$1.call(JerseyInvocation.java:668)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:228)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:444)
	at org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:668)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:402)
	at org.glassfish.jersey.client.JerseyInvocation$Builder.get(JerseyInvocation.java:302)
	at com.knime.bigdata.spark.jobserver.client.WsRsRestClient.toJSONArray(WsRsRestClient.java:125)
	at com.knime.bigdata.spark.jobserver.client.RestClient.toJSONArray(RestClient.java:80)
	at com.knime.bigdata.spark.jobserver.client.KnimeContext.sparkContextExists(KnimeContext.java:70)
	at com.knime.bigdata.spark.node.AbstractSparkNodeModel.loadInternals(AbstractSparkNodeModel.java:181)
	... 63 more
2015-06-03 18:05:37,314 : ERROR : main : MLlib Predictor : MLlib Predictor : 0:59 : Configure failed (NullPointerException): null
2015-06-03 18:05:37,314 : DEBUG : main : MLlib Predictor : MLlib Predictor : 0:59 : Configure failed (NullPointerException): null
java.lang.NullPointerException
	at org.knime.core.data.DataTableSpec.getUniqueColumnName(DataTableSpec.java:992)
	at com.knime.bigdata.spark.node.mllib.clustering.assigner.MLlibClusterAssignerNodeModel.createSpec(MLlibClusterAssignerNodeModel.java:109)
	at com.knime.bigdata.spark.node.mllib.clustering.assigner.MLlibClusterAssignerNodeModel.configure(MLlibClusterAssignerNodeModel.java:84)
	at org.knime.core.node.NodeModel.configureModel(NodeModel.java:1033)
	at org.knime.core.node.Node.invokeNodeModelConfigure(Node.java:1746)
	at org.knime.core.node.Node.configure(Node.java:1682)
	at org.knime.core.node.workflow.NativeNodeContainer.performConfigure(NativeNodeContainer.java:524)
	at org.knime.core.node.workflow.SingleNodeContainer.callNodeConfigure(SingleNodeContainer.java:282)
	at org.knime.core.node.workflow.SingleNodeContainer.configure(SingleNodeContainer.java:176)
	at org.knime.core.node.workflow.WorkflowManager.configureSingleNodeContainer(WorkflowManager.java:5703)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7590)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.postLoad(WorkflowManager.java:7553)
	at org.knime.core.node.workflow.WorkflowManager.loadContent(WorkflowManager.java:7425)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7379)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7304)
	at org.knime.core.node.workflow.WorkflowManager.load(WorkflowManager.java:7277)
	at org.knime.core.node.workflow.WorkflowManager.loadProject(WorkflowManager.java:7115)
	at org.knime.workbench.editor2.LoadWorkflowRunnable.run(LoadWorkflowRunnable.java:154)
	at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:464)
	at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:372)
	at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:507)
	at org.eclipse.ui.internal.progress.ProgressMonitorJobsDialog.run(ProgressMonitorJobsDialog.java:275)
	at org.eclipse.ui.internal.progress.ProgressManager$5.run(ProgressManager.java:960)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:995)
	at org.eclipse.ui.internal.progress.ProgressManager.busyCursorWhile(ProgressManager.java:970)
	at org.knime.workbench.editor2.WorkflowEditor.setInput(WorkflowEditor.java:1093)
	at org.knime.workbench.editor2.WorkflowEditor.init(WorkflowEditor.java:405)
	at org.eclipse.ui.internal.EditorManager.createSite(EditorManager.java:828)
	at org.eclipse.ui.internal.EditorReference.createPartHelper(EditorReference.java:647)
	at org.eclipse.ui.internal.EditorReference.createPart(EditorReference.java:465)
	at org.eclipse.ui.internal.WorkbenchPartReference.getPart(WorkbenchPartReference.java:595)
	at org.eclipse.ui.internal.EditorAreaHelper.setVisibleEditor(EditorAreaHelper.java:271)
	at org.eclipse.ui.internal.EditorManager.setVisibleEditor(EditorManager.java:1459)
	at org.eclipse.ui.internal.EditorManager$5.runWithException(EditorManager.java:972)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:803)
	at org.eclipse.ui.internal.Workbench$33.runWithException(Workbench.java:1600)
	at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:31)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2609)
	at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499)
	at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:134)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1410)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1386)
